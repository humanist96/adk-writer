"""
Multi-Model AI Financial Writer Pro - Streamlit Cloud Version
Supports Anthropic Claude, OpenAI GPT, and Google Gemini
"""

import streamlit as st
from typing import Dict, Any, Optional
import json
from datetime import datetime
from pathlib import Path
import time
from loguru import logger

# Page configuration
st.set_page_config(
    page_title="AI Financial Writer Pro - Multi Model",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Try cloud config first, fallback to local
try:
    from src.config_cloud import config
except:
    from src.config import config

from src.agents.multi_model_agents import (
    ModelFactory,
    MultiModelAgent,
    MultiModelAgentResponse
)
from src.agents.loop_agent import LoopAgent
from src.tools.custom_tools import (
    validate_financial_terms,
    check_compliance,
    calculate_quality_score
)
from src.utils.diff_utils import (
    create_diff_html,
    create_word_diff,
    extract_modifications,
    create_modification_summary,
    get_change_statistics,
    calculate_similarity
)
from src.database import get_db_manager
from src.utils.example_templates import ExampleTemplates

# Custom CSS for modern UI
st.markdown("""
<style>
    /* Main App Styling */
    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    /* Header Styling */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2.5rem;
        border-radius: 20px;
        margin-bottom: 2rem;
        color: white;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        animation: slideDown 0.5s ease-out;
    }
    
    @keyframes slideDown {
        from {
            opacity: 0;
            transform: translateY(-20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Card Styling */
    .stat-card {
        background: white;
        border-radius: 16px;
        padding: 1.5rem;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
        margin-bottom: 1rem;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        border: 1px solid rgba(255, 255, 255, 0.8);
    }
    
    .stat-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }
    
    /* Model Selection Cards */
    .model-selector {
        background: white;
        border-radius: 12px;
        padding: 1rem;
        margin: 0.5rem 0;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .model-selector:hover {
        border-color: #667eea;
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
    }
    
    .model-selector.selected {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: #667eea;
    }
    
    /* Provider Badges */
    .provider-badge {
        display: inline-block;
        padding: 0.4rem 1rem;
        border-radius: 25px;
        font-size: 0.875rem;
        font-weight: 600;
        margin: 0.25rem;
        transition: all 0.3s ease;
    }
    
    .provider-badge:hover {
        transform: scale(1.05);
    }
    
    .anthropic-badge {
        background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);
        color: white;
    }
    
    .openai-badge {
        background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
        color: white;
    }
    
    .google-badge {
        background: linear-gradient(135deg, #4285f4 0%, #34a853 100%);
        color: white;
    }
    
    /* Metric Values */
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: pulse 2s ease-in-out infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.8; }
    }
    
    /* Button Styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.8rem 2rem;
        border-radius: 12px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* Sidebar Styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Tab Styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 12px;
        padding: 0.5rem 1.5rem;
        background: white;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: transparent;
    }
    
    /* Success/Error Messages */
    .stSuccess {
        background: linear-gradient(135deg, #00b894 0%, #00cec9 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    .stError {
        background: linear-gradient(135deg, #ff7675 0%, #d63031 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    /* Text Area Styling */
    .stTextArea textarea {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTextArea textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Select Box Styling */
    .stSelectbox > div > div {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
</style>
""", unsafe_allow_html=True)

class MultiModelFinancialWritingApp:
    """Multi-Model Financial Writing AI Application"""
    
    def __init__(self):
        self.config = config
        self.multi_model_agent = None
        self.db = get_db_manager()  # Initialize database manager
        self.example_templates = ExampleTemplates()  # Initialize example templates
        self._initialize_session_state()
        self._load_statistics_from_db()
    
    def _initialize_session_state(self):
        """Initialize session state variables"""
        if 'history' not in st.session_state:
            st.session_state.history = []
        if 'current_result' not in st.session_state:
            st.session_state.current_result = None
        if 'stats' not in st.session_state:
            st.session_state.stats = {
                'total_documents': 0,
                'avg_quality': 0,
                'avg_iterations': 0,
                'total_time': 0,
                'models_used': {}
            }
        if 'selected_provider' not in st.session_state:
            st.session_state.selected_provider = config.DEFAULT_PROVIDER
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = config.ANTHROPIC_MODEL if config.DEFAULT_PROVIDER == "Anthropic" else None
        if 'draft_document' not in st.session_state:
            st.session_state.draft_document = None
        if 'refinement_history' not in st.session_state:
            st.session_state.refinement_history = []
        if 'critique_history' not in st.session_state:
            st.session_state.critique_history = []
    
    def _load_statistics_from_db(self):
        """Load statistics from database"""
        try:
            db_stats = self.db.get_statistics(days=30)
            st.session_state.stats = {
                'total_documents': db_stats['total_documents'],
                'avg_quality': db_stats['avg_quality'],
                'avg_iterations': db_stats['avg_iterations'],
                'total_time': db_stats['total_time'],
                'models_used': db_stats.get('by_provider', {}),
                'daily_stats': db_stats.get('daily_stats', []),
                'by_document_type': db_stats.get('by_document_type', {})
            }
        except Exception as e:
            logger.warning(f"Could not load statistics from database: {str(e)}")
    
    def render_header(self):
        """Render animated header"""
        st.markdown("""
        <div class="main-header">
            <h1 style="margin: 0; font-size: 2.8rem; font-weight: 800;">
                ü§ñ AI Financial Writer Pro
            </h1>
            <p style="margin-top: 0.8rem; font-size: 1.2rem; opacity: 0.95;">
                Ï∞®ÏÑ∏ÎåÄ Í∏àÏúµ Î¨∏ÏÑú ÏûëÏÑ± AI ÌîåÎû´Ìèº
            </p>
            <div style="margin-top: 1rem;">
                <span class="provider-badge anthropic-badge">Anthropic Claude</span>
                <span class="provider-badge openai-badge">OpenAI GPT</span>
                <span class="provider-badge google-badge">Google Gemini</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar_model_selector(self):
        """Render model selection in sidebar"""
        st.sidebar.markdown("## ü§ñ AI Î™®Îç∏ ÏÑ§Ï†ï")
        
        available_models = ModelFactory.get_available_models()
        providers_available = []
        
        # Check available providers
        if config.ANTHROPIC_API_KEY:
            providers_available.append("Anthropic")
        if config.OPENAI_API_KEY:
            providers_available.append("OpenAI")
        if config.GOOGLE_API_KEY:
            providers_available.append("Google")
        
        if not providers_available:
            st.sidebar.error("‚ö†Ô∏è API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            return providers_available
        
        # Provider selection
        st.sidebar.markdown("### üì¶ AI Ï†úÍ≥µÏûê")
        selected_provider = st.sidebar.radio(
            "Ï†úÍ≥µÏûê ÏÑ†ÌÉù",
            options=providers_available,
            index=providers_available.index(st.session_state.selected_provider) if st.session_state.selected_provider in providers_available else 0,
            label_visibility="collapsed",
            help="ÏÇ¨Ïö©Ìï† AI Ï†úÍ≥µÏûêÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
        )
        
        if selected_provider != st.session_state.selected_provider:
            st.session_state.selected_provider = selected_provider
            st.session_state.selected_model = None
            st.rerun()
        
        # Model selection for current provider
        if selected_provider in available_models:
            st.sidebar.markdown("### üéØ Î™®Îç∏ ÏÑ†ÌÉù")
            
            models = available_models[selected_provider]
            model_options = list(models.keys())
            model_labels = list(models.values())
            
            # Set default model index
            if st.session_state.selected_model and st.session_state.selected_model in model_options:
                default_index = model_options.index(st.session_state.selected_model)
            else:
                default_index = 0
                st.session_state.selected_model = model_options[0]
            
            selected_model = st.sidebar.selectbox(
                "Î™®Îç∏",
                options=model_options,
                format_func=lambda x: models[x],
                index=default_index,
                label_visibility="collapsed",
                help="ÏÇ¨Ïö©Ìï† AI Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            if selected_model != st.session_state.selected_model:
                st.session_state.selected_model = selected_model
            
            # Model features
            with st.sidebar.expander("üåü Î™®Îç∏ ÌäπÏßï", expanded=False):
                if selected_provider == "Anthropic":
                    st.markdown("""
                    **Claude ÌäπÏßï:**
                    - üìö Í∏¥ Ïª®ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨ (200K ÌÜ†ÌÅ∞)
                    - üéØ ÎÜíÏùÄ Ï†ïÌôïÎèÑÏôÄ ÏùºÍ¥ÄÏÑ±
                    - üí° Îõ∞Ïñ¥ÎÇú Ï∂îÎ°† Îä•Î†•
                    - üîí ÏïàÏ†ÑÌïòÍ≥† Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî ÏùëÎãµ
                    """)
                elif selected_provider == "OpenAI":
                    st.markdown("""
                    **GPT ÌäπÏßï:**
                    - üåç Îã§ÏñëÌïú Ïñ∏Ïñ¥ ÏßÄÏõê
                    - üé® Ï∞ΩÏùòÏ†ÅÏù∏ ÏΩòÌÖêÏ∏† ÏÉùÏÑ±
                    - üîß Í∞ïÎ†•Ìïú ÏΩîÎìú ÏÉùÏÑ±
                    - üìä Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Îä•Î†•
                    """)
                elif selected_provider == "Google":
                    st.markdown("""
                    **Gemini ÌäπÏßï:**
                    - ‚ö° Îπ†Î•∏ ÏùëÎãµ ÏÜçÎèÑ
                    - üñºÔ∏è Î©ÄÌã∞Î™®Îã¨ ÏßÄÏõê
                    - üí∞ ÎπÑÏö© Ìö®Ïú®Ï†Å
                    - üîÑ Ïã§ÏãúÍ∞Ñ ÏóÖÎç∞Ïù¥Ìä∏
                    """)
        
        return providers_available
    
    def render_stats(self):
        """Render animated statistics"""
        st.markdown("### üìä ÌÜµÍ≥Ñ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "üìÑ Ï¥ù ÏÉùÏÑ± Î¨∏ÏÑú",
                st.session_state.stats['total_documents'],
                "+1" if st.session_state.stats['total_documents'] > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            quality_value = st.session_state.stats['avg_quality']
            quality_delta = (quality_value - 0.7) * 100 if quality_value > 0 else 0
            st.metric(
                "‚≠ê ÌèâÍ∑† ÌíàÏßà",
                f"{quality_value:.1%}",
                f"+{quality_delta:.0f}%" if quality_delta > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "üîÑ ÌèâÍ∑† Î∞òÎ≥µ",
                f"{st.session_state.stats['avg_iterations']:.1f}Ìöå",
                None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            if st.session_state.stats['models_used']:
                most_used = max(st.session_state.stats['models_used'].items(), key=lambda x: x[1])
                st.metric(
                    "üèÜ Ï£º ÏÇ¨Ïö© Î™®Îç∏",
                    most_used[0].split(' - ')[0],
                    f"{most_used[1]}Ìöå"
                )
            else:
                st.metric("üèÜ Ï£º ÏÇ¨Ïö© Î™®Îç∏", "-", None)
            st.markdown('</div>', unsafe_allow_html=True)
    
    def process_document(self, input_data: Dict[str, Any], is_refinement: bool = False, use_loop_agent: bool = True) -> Dict[str, Any]:
        """Process document through the pipeline with optional LoopAgent"""
        try:
            # Initialize multi-model agent if not already done
            if not self.multi_model_agent:
                agent_config = config.get_agent_config()
                self.multi_model_agent = MultiModelAgent(agent_config)
            
            # Show progress with animation
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # Get selected provider and model
            provider = st.session_state.selected_provider
            model = st.session_state.selected_model
            
            if model:
                # Update config with selected model
                if provider == "Anthropic":
                    self.multi_model_agent.config['anthropic_model'] = model
                elif provider == "OpenAI":
                    self.multi_model_agent.config['openai_model'] = model
                elif provider == "Google":
                    self.multi_model_agent.config['google_model'] = model
            
            # Animated progress
            with progress_placeholder.container():
                progress_bar = st.progress(0)
                for i in range(0, 101, 5):
                    progress_bar.progress(i)
                    if i < 30:
                        status_placeholder.info(f"üîß Î™®Îç∏ Ï§ÄÎπÑ Ï§ë... ({provider})")
                    elif i < 70:
                        status_placeholder.info(f"‚úçÔ∏è Î¨∏ÏÑú ÏÉùÏÑ± Ï§ë... ({provider})")
                    else:
                        status_placeholder.info("üîç ÌíàÏßà Í≤ÄÏ¶ù Ï§ë...")
                    time.sleep(0.1)
            
            # Check if we should use LoopAgent for iterative improvement
            if use_loop_agent and not is_refinement:
                # Use LoopAgent for comprehensive critique and refinement
                status_placeholder.info("üîÑ ADK LoopAgentÎ°ú Î¨∏ÏÑúÎ•º Î∞òÎ≥µÏ†ÅÏúºÎ°ú Í∞úÏÑ†ÌïòÎäî Ï§ë...")
                
                # Prepare config for LoopAgent
                loop_config = config.get_agent_config()
                loop_config['provider'] = provider
                loop_config['model'] = model
                
                # Also set provider-specific model keys
                if provider == "Anthropic":
                    loop_config['anthropic_model'] = model
                elif provider == "OpenAI":
                    loop_config['openai_model'] = model
                elif provider == "Google":
                    loop_config['google_model'] = model
                
                # Create and run LoopAgent
                from src.agents.loop_agent import LoopAgent
                loop_agent = LoopAgent(loop_config)
                
                # Run the loop agent with comprehensive improvement
                loop_result = loop_agent.run({
                    "document_type": input_data.get('document_type'),
                    "context": input_data.get('requirements'),
                    "tone": input_data.get('tone'),
                    "recipient": input_data.get('recipient', ''),
                    "subject": input_data.get('subject', ''),
                    "additional_context": input_data.get('additional_context', ''),
                    "provider": provider,
                    "model": model
                })
                
                # Extract results
                final_doc = loop_result.get('final_document', '')
                quality_score = loop_result.get('quality_score', 0.0)
                iterations = loop_result.get('iterations', 1)
                
                # Save draft from first iteration
                if loop_result.get('history') and len(loop_result['history']) > 0:
                    first_iteration = loop_result['history'][0].get('result', {})
                    draft_doc = first_iteration.get('draft', final_doc)
                    st.session_state.draft_document = draft_doc
                    st.session_state.refinement_history = [{
                        'version': 'Ï¥àÏïà',
                        'content': draft_doc,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {model}"
                    }]
                    
                    # Save critique history for diff analysis
                    st.session_state.critique_history = []
                    
                    # Add refinement history from loop iterations
                    for i, hist in enumerate(loop_result['history'], 1):
                        result = hist.get('result', {})
                        refined_content = result.get('refined_content', '')
                        critique = result.get('critique', '')
                        
                        if refined_content:
                            st.session_state.refinement_history.append({
                                'version': f'Í∞úÏÑ† {i}',
                                'content': refined_content,
                                'timestamp': hist.get('timestamp', datetime.now().isoformat()),
                                'model': f"{provider} - {model}",
                                'quality_score': result.get('quality_score', 0)
                            })
                        
                        if critique:
                            st.session_state.critique_history.append({
                                'iteration': i,
                                'critique': critique,
                                'quality_score': result.get('quality_score', 0),
                                'issues': result.get('issues_found', []),
                                'suggestions': result.get('suggestions', [])
                            })
                
                # Update status
                status_placeholder.success(
                    f"‚úÖ LoopAgent ÏôÑÎ£å! "
                    f"Ï¥ù {iterations}Ìöå Î∞òÎ≥µ, "
                    f"ÌíàÏßà Ï†êÏàò: {quality_score:.2f}, "
                    f"Ï¢ÖÎ£å ÏÇ¨Ïú†: {loop_result.get('exit_reason', 'Unknown')}"
                )
                
            else:
                # Simple generation without LoopAgent
                prompt = self._create_prompt(input_data)
                
                # Generate response
                response = self.multi_model_agent.generate(
                    prompt,
                    provider=provider,
                    temperature=input_data.get('temperature', 0.7),
                    max_tokens=input_data.get('max_tokens', 2048)
                )
                
                final_doc = response.content
                
                # Save draft if first generation
                if not is_refinement and not st.session_state.draft_document:
                    st.session_state.draft_document = response.content
                    st.session_state.refinement_history = [{
                        'version': 'Ï¥àÏïà',
                        'content': response.content,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {response.model_used}"
                    }]
                
                # Calculate quality score for simple generation
                term_validation = validate_financial_terms(final_doc)
                compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
                quality_score = calculate_quality_score(final_doc, term_validation, compliance_check)
                iterations = 1
            
            # Clear progress
            progress_placeholder.empty()
            status_placeholder.empty()
            
            # Final validation (for all paths)
            term_validation = validate_financial_terms(final_doc)
            compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
            final_score = quality_score if use_loop_agent and not is_refinement else calculate_quality_score(final_doc, term_validation, compliance_check)
            
            # Update model usage stats
            model_used = model if use_loop_agent and not is_refinement else response.model_used if 'response' in locals() else model
            model_key = f"{provider} - {model_used}"
            if model_key not in st.session_state.stats['models_used']:
                st.session_state.stats['models_used'][model_key] = 0
            st.session_state.stats['models_used'][model_key] += 1
            
            result = {
                "success": True,
                "final_document": final_doc,
                "quality_score": final_score,
                "iterations": iterations if 'iterations' in locals() else 1,
                "total_time": 5.0,
                "provider": provider,
                "model_used": model_used,
                "validation": {
                    "terms": term_validation,
                    "compliance": compliance_check,
                    "final_score": final_score
                }
            }
            
            # Update stats
            self._update_stats(result)
            
            return result
            
        except Exception as e:
            progress_placeholder.empty()
            status_placeholder.empty()
            return {"error": str(e), "success": False}
    
    def _create_prompt(self, input_data: Dict[str, Any]) -> str:
        """Create prompt for document generation"""
        doc_type = config.DOCUMENT_TYPES.get(input_data['document_type'], input_data['document_type'])
        
        prompt = f"""ÎãπÏã†ÏùÄ ÏΩîÏä§ÏΩ§ Í∏àÏúµÏòÅÏóÖÎ∂ÄÏùò Ï†ÑÎ¨∏ Î¨∏ÏÑú ÏûëÏÑ± AIÏûÖÎãàÎã§.
        
Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Í≥º Ï∂îÍ∞Ä Ï†ïÎ≥¥Î•º Î™®Îëê Î∞òÏòÅÌïòÏó¨ {doc_type}ÏùÑ(Î•º) ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

[ÌïµÏã¨ ÏöîÍµ¨ÏÇ¨Ìï≠]
{input_data['requirements']}

[Î¨∏ÏÑú Ïä§ÌÉÄÏùº]
ÌÜ§Ïï§Îß§ÎÑà: {input_data['tone']}
"""
        
        if input_data.get('recipient'):
            prompt += f"\n\n[ÏàòÏã†Ïûê Ï†ïÎ≥¥]\nÏàòÏã†Ïûê: {input_data['recipient']}"
            prompt += "\n- ÏàòÏã†ÏûêÏóêÍ≤å Ï†ÅÌï©Ìïú Ìò∏Ïπ≠Í≥º Ï°¥Ïπ≠ÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî"
            prompt += "\n- ÏàòÏã†ÏûêÏùò ÏûÖÏû•Í≥º Í¥ÄÏã¨ÏÇ¨Î•º Í≥†Î†§ÌïòÏó¨ ÏûëÏÑ±ÌïòÏÑ∏Ïöî"
        
        if input_data.get('subject'):
            prompt += f"\n\n[Ï†úÎ™©/Ï£ºÏ†ú]\n{input_data['subject']}"
            prompt += "\n- Ï†úÎ™©Í≥º ÏùºÍ¥ÄÏÑ± ÏûàÎäî ÎÇ¥Ïö©ÏúºÎ°ú Íµ¨ÏÑ±ÌïòÏÑ∏Ïöî"
            prompt += "\n- ÌïµÏã¨ Î©îÏãúÏßÄÍ∞Ä Î™ÖÌôïÌûà Ï†ÑÎã¨ÎêòÎèÑÎ°ù ÏûëÏÑ±ÌïòÏÑ∏Ïöî"
        
        if input_data.get('additional_context'):
            prompt += f"\n\n[Ï∂îÍ∞Ä Ïª®ÌÖçÏä§Ìä∏ Î∞è ÌäπÎ≥Ñ ÏßÄÏãúÏÇ¨Ìï≠]\n{input_data['additional_context']}"
            prompt += "\n- Ï∂îÍ∞Ä Ïª®ÌÖçÏä§Ìä∏Ïùò ÎÇ¥Ïö©ÏùÑ Î∞òÎìúÏãú Î∞òÏòÅÌïòÏÑ∏Ïöî"
            prompt += "\n- ÌäπÎ≥ÑÌûà Í∞ïÏ°∞Îêú ÏÇ¨Ìï≠ÏùÄ Î¨∏ÏÑúÏóêÏÑú Î∂ÄÍ∞ÅÏãúÏºú Ï£ºÏÑ∏Ïöî"
        
        # Add length preference
        length_pref = input_data.get('length_preference', 'medium')
        
        prompt += """

[ÏûëÏÑ± Í∏∞Ï§Ä]
1. ÏöîÍµ¨ÏÇ¨Ìï≠Ïùò Î™®Îì† ÎÇ¥Ïö©ÏùÑ Îπ†ÏßêÏóÜÏù¥ Î∞òÏòÅ
2. Ï∂îÍ∞Ä Ï†ïÎ≥¥ÏôÄ Ïª®ÌÖçÏä§Ìä∏Î•º Ï†ÅÏ†àÌûà ÌôúÏö©
3. Í∏àÏúµ Ï†ÑÎ¨∏ Ïö©Ïñ¥Î•º Ï†ïÌôïÌïòÍ≤å ÏÇ¨Ïö©
4. Í∑úÏ†ï Ï§ÄÏàò Î∞è Î≤ïÏ†Å ÏöîÍµ¨ÏÇ¨Ìï≠ Ï∂©Ï°±
5. Î™ÖÌôïÌïòÍ≥† ÎÖºÎ¶¨Ï†ÅÏù∏ Î¨∏Ïû• Íµ¨ÏÑ±
6. Ï†ÅÏ†àÌïú Íµ¨Ï°∞ÏôÄ ÌòïÏãù Ï§ÄÏàò
7. Ï†ÑÎ¨∏Ï†ÅÏù¥Î©¥ÏÑúÎèÑ Ïù¥Ìï¥ÌïòÍ∏∞ Ïâ¨Ïö¥ ÌëúÌòÑ
8. ÏΩîÏä§ÏΩ§ Í∏àÏúµÏòÅÏóÖÎ∂ÄÏùò Ï†ÑÎ¨∏ÏÑ±Í≥º Ïã†Î¢∞ÏÑ± Î∞òÏòÅ
"""
        
        # Add length-specific instructions
        if length_pref == "short":
            prompt += "\n[Î¨∏ÏÑú Í∏∏Ïù¥] ‚ö° Í∞ÑÍ≤∞ÌïòÍ≥† ÌïµÏã¨Ï†ÅÏù∏ ÎÇ¥Ïö©ÏúºÎ°ú 1-2Îã®ÎùΩ Ïù¥ÎÇ¥Î°ú ÏûëÏÑ±"
        elif length_pref == "long":
            prompt += "\n[Î¨∏ÏÑú Í∏∏Ïù¥] üìö ÏÉÅÏÑ∏ÌïòÍ≥† Ï¢ÖÌï©Ï†ÅÏù∏ ÎÇ¥Ïö©ÏúºÎ°ú 5-7Îã®ÎùΩ Ïù¥ÏÉÅ ÏûëÏÑ±"
        else:
            prompt += "\n[Î¨∏ÏÑú Í∏∏Ïù¥] üìÑ Ï†ÅÏ†àÌïú Í∏∏Ïù¥Î°ú 3-4Îã®ÎùΩ Ï†ïÎèÑÎ°ú ÏûëÏÑ±"
        
        prompt += """

Î∞úÏã†: ÏΩîÏä§ÏΩ§ Í∏àÏúµÏòÅÏóÖÎ∂Ä

Î¨∏ÏÑúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:
"""
        
        return prompt
    
    def _update_stats(self, result: Dict[str, Any]):
        """Update statistics"""
        # Update session state stats
        stats = st.session_state.stats
        stats['total_documents'] += 1
        
        current_quality = result.get('quality_score', 0)
        stats['avg_quality'] = (
            (stats['avg_quality'] * (stats['total_documents'] - 1) + current_quality) 
            / stats['total_documents']
        )
        
        current_iter = result.get('iterations', 0)
        stats['avg_iterations'] = (
            (stats['avg_iterations'] * (stats['total_documents'] - 1) + current_iter)
            / stats['total_documents']
        )
        
        stats['total_time'] += result.get('total_time', 0)
        
        # Stats are also automatically updated in database when saving document
    
    def run(self):
        """Run the application"""
        # Header
        self.render_header()
        
        # Sidebar with model selection and settings
        with st.sidebar:
            st.markdown("---")
            
            # Model selector in sidebar
            providers_available = self.render_sidebar_model_selector()
            
            if not providers_available:
                st.stop()
            
            st.markdown("---")
            
            # Model settings
            st.markdown("## ‚öôÔ∏è Î™®Îç∏ ÏÑ§Ï†ï")
            
            temperature = st.slider(
                "üå°Ô∏è Temperature (Ï∞ΩÏùòÏÑ±)",
                min_value=0.0,
                max_value=1.0,
                value=config.TEMPERATURE,
                step=0.1,
                help="ÎÇÆÏùÑÏàòÎ°ù ÏùºÍ¥ÄÏÑ± ÏûàÍ≥†, ÎÜíÏùÑÏàòÎ°ù Ï∞ΩÏùòÏ†ÅÏûÖÎãàÎã§"
            )
            
            max_tokens = st.number_input(
                "üìù ÏµúÎåÄ ÌÜ†ÌÅ∞ Ïàò",
                min_value=500,
                max_value=4000,
                value=config.MAX_OUTPUT_TOKENS,
                step=100,
                help="ÏÉùÏÑ±Ìï† ÌÖçÏä§Ìä∏Ïùò ÏµúÎåÄ Í∏∏Ïù¥"
            )
            
            st.markdown("---")
            
            # Document settings
            st.markdown("## üìÑ Î¨∏ÏÑú ÏÑ§Ï†ï")
            
            doc_type = st.selectbox(
                "Î¨∏ÏÑú Ïú†Ìòï",
                options=list(config.DOCUMENT_TYPES.keys()),
                format_func=lambda x: config.DOCUMENT_TYPES[x],
                help="ÏûëÏÑ±Ìï† Î¨∏ÏÑúÏùò Ïú†ÌòïÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            tone = st.select_slider(
                "ÌÜ§Ïï§Îß§ÎÑà",
                options=["formal", "professional", "professional_premium", "analytical", "urgent", "friendly"],
                value=st.session_state.get('example_tone', 'professional'),
                format_func=lambda x: {
                    "formal": "Í≤©ÏãùÏûàÎäî",
                    "professional": "Ï†ÑÎ¨∏Ï†ÅÏù∏",
                    "professional_premium": "ÌîÑÎ¶¨ÎØ∏ÏóÑ (VIPÏö©)",
                    "analytical": "Î∂ÑÏÑùÏ†ÅÏù∏",
                    "urgent": "Í∏¥Í∏âÌïú",
                    "friendly": "ÏπúÍ∑ºÌïú"
                }.get(x, x),
                help="Î¨∏ÏÑúÏùò ÌÜ§ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            # Document length preference
            doc_length = st.select_slider(
                "üìè Î¨∏ÏÑú Í∏∏Ïù¥",
                options=["short", "medium", "long"],
                value="medium",
                format_func=lambda x: {
                    "short": "Í∞ÑÍ≤∞ (1-2Îã®ÎùΩ)",
                    "medium": "Î≥¥ÌÜµ (3-4Îã®ÎùΩ)",
                    "long": "ÏÉÅÏÑ∏ (5-7Îã®ÎùΩ+)"
                }.get(x, x),
                help="ÏÉùÏÑ±Ìï† Î¨∏ÏÑúÏùò Í∏∏Ïù¥Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            # Advanced prompt settings
            with st.expander("üß™ Í≥†Í∏â ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï", expanded=False):
                use_context7 = st.checkbox(
                    "üìö Context7 Ìå®ÌÑ¥ ÏÇ¨Ïö©",
                    value=True,
                    help="Context7 Î¨∏ÏÑú Íµ¨Ï°∞ Ìå®ÌÑ¥Í≥º Í∏àÏúµ Ï†ÑÎ¨∏ Ïö©Ïñ¥Î•º Ï†ÅÏö©Ìï©ÎãàÎã§"
                )
                
                use_sequential = st.checkbox(
                    "üîÑ Sequential Thinking ÏÇ¨Ïö©",
                    value=True,
                    help="Ï≤¥Í≥ÑÏ†ÅÏù∏ ÏàúÏ∞® ÏÇ¨Í≥† ÌîÑÎ†àÏûÑÏõåÌÅ¨Î•º Ï†ÅÏö©Ìï©ÎãàÎã§"
                )
                
                if st.button("üéØ Í≥†Í∏â ÌîÑÎ°¨ÌîÑÌä∏ Ï†ÅÏö©", use_container_width=True):
                    # Get current requirements from session state if available
                    current_requirements = st.session_state.get('requirements_input', '')
                    if current_requirements:
                        # Build a temporary example from current inputs
                        temp_example = {
                            'title': doc_type,
                            'requirements': current_requirements,
                            'recipient': st.session_state.get('recipient_input', ''),
                            'subject': st.session_state.get('subject_input', ''),
                            'additional_context': st.session_state.get('context_input', ''),
                            'tone': tone,
                            'length': doc_length
                        }
                        
                        enhanced_prompt = self.example_templates.generate_advanced_prompt(
                            temp_example,
                            use_context7=use_context7,
                            use_sequential=use_sequential,
                            length_preference=doc_length
                        )
                        
                        st.session_state.example_requirements = enhanced_prompt
                        st.success("‚ú® Í≥†Í∏â ÌîÑÎ°¨ÌîÑÌä∏Í∞Ä Ï†ÅÏö©ÎêòÏóàÏäµÎãàÎã§!")
                        st.rerun()
                    else:
                        st.warning("Î®ºÏ†Ä ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
            
            st.markdown("---")
            
            # Quick actions
            st.markdown("## üöÄ Îπ†Î•∏ Ïã§Ìñâ")
            
            if st.button("üîÑ Ï¥àÍ∏∞Ìôî", use_container_width=True):
                st.session_state.history = []
                st.session_state.current_result = None
                st.rerun()
            
            if st.button("üìä ÌÜµÍ≥Ñ Ï¥àÍ∏∞Ìôî", use_container_width=True):
                st.session_state.stats = {
                    'total_documents': 0,
                    'avg_quality': 0,
                    'avg_iterations': 0,
                    'total_time': 0,
                    'models_used': {}
                }
                st.rerun()
        
        # Main content area
        st.markdown("---")
        
        # Stats dashboard
        self.render_stats()
        
        st.markdown("---")
        
        # Tabs for different features
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "‚úçÔ∏è Î¨∏ÏÑú ÏûëÏÑ±",
            "üîÑ Ï¥àÏïà vs ÏµúÏ¢Ö",
            "üîÄ Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ Î∂ÑÏÑù",
            "üîç Î™®Îç∏ ÎπÑÍµê",
            "üìä Î∂ÑÏÑù",
            "üìö Ïù¥Î†•"
        ])
        
        with tab1:
            col1, col2 = st.columns([1, 1], gap="large")
            
            with col1:
                st.markdown("### üìù Î¨∏ÏÑú ÏöîÍµ¨ÏÇ¨Ìï≠")
                
                # Use example values if available
                req_value = st.session_state.get('example_requirements', '')
                requirements = st.text_area(
                    "ÏöîÍµ¨ÏÇ¨Ìï≠",
                    value=req_value,
                    placeholder="ÏûëÏÑ±ÌïòÍ≥†Ïûê ÌïòÎäî Î¨∏ÏÑúÏùò ÎÇ¥Ïö©Í≥º ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî...\n\nÏòàÏãú:\n- Ïã†Í∑ú Í∏àÏúµ ÏÉÅÌíà ÏïàÎÇ¥ Ïù¥Î©îÏùº\n- Ìà¨Ïûê Ï†úÏïàÏÑú Ï¥àÏïà\n- Í∑úÏ†ï Ï§ÄÏàò Î≥¥Í≥†ÏÑú",
                    height=250,
                    label_visibility="collapsed",
                    key="requirements_input"
                )
                
                # Check if we have example data
                has_example = any([
                    'example_recipient' in st.session_state,
                    'example_subject' in st.session_state,
                    'example_context' in st.session_state
                ])
                
                with st.expander("üìé Ï∂îÍ∞Ä Ï†ïÎ≥¥", expanded=has_example):
                    recipient = st.text_input(
                        "ÏàòÏã†Ïûê",
                        value=st.session_state.get('example_recipient', ''),
                        placeholder="Ïòà: ÍπÄÏ≤†Ïàò ÎåÄÌëúÎãò",
                        key="recipient_input"
                    )
                    subject = st.text_input(
                        "Ï†úÎ™©",
                        value=st.session_state.get('example_subject', ''),
                        placeholder="Ïòà: 2024ÎÖÑ Ïã†Í∑ú Ìà¨Ïûê ÏÉÅÌíà ÏïàÎÇ¥",
                        key="subject_input"
                    )
                    additional_context = st.text_area(
                        "Ï∂îÍ∞Ä Ïª®ÌÖçÏä§Ìä∏",
                        value=st.session_state.get('example_context', ''),
                        placeholder="ÌäπÎ≥ÑÌûà Í∞ïÏ°∞ÌïòÍ±∞ÎÇò Ìè¨Ìï®Ìï¥Ïïº Ìï† ÎÇ¥Ïö©ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî...",
                        height=100,
                        key="context_input"
                    )
                
                # Clean up example data after use
                if req_value and requirements != req_value:
                    for key in ['example_requirements', 'example_recipient', 'example_subject', 'example_context', 'example_tone']:
                        if key in st.session_state:
                            del st.session_state[key]
                
                # LoopAgent ÏÇ¨Ïö© ÏòµÏÖò
                use_loop = st.checkbox(
                    "üîÑ ADK LoopAgentÎ°ú ÎπÑÌèâ Î∞è Í∞úÏÑ† ÏàòÌñâ",
                    value=True,
                    help="Ï≤¥ÌÅ¨ÌïòÎ©¥ Î¨∏ÏÑúÎ•º Ïó¨Îü¨ Î≤à ÎπÑÌèâÌïòÍ≥† Í∞úÏÑ†ÌïòÏó¨ ÌíàÏßàÏùÑ ÎÜíÏûÖÎãàÎã§."
                )
                
                col1_1, col1_2 = st.columns(2)
                with col1_1:
                    if st.button("üöÄ Î¨∏ÏÑú ÏÉùÏÑ±", type="primary", use_container_width=True):
                        if requirements:
                            if not st.session_state.selected_model:
                                st.warning("Î®ºÏ†Ä ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú AI Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.")
                            else:
                                input_data = {
                                    "document_type": doc_type,
                                    "requirements": requirements,
                                    "tone": tone,
                                    "recipient": recipient,
                                    "subject": subject,
                                    "additional_context": additional_context,
                                    "temperature": temperature,
                                    "max_tokens": max_tokens,
                                    "length_preference": doc_length
                                }
                                
                                result = self.process_document(input_data, use_loop_agent=use_loop)
                                
                                st.session_state.current_result = result
                                # Save to database
                                doc_data = {
                                    "timestamp": datetime.now().isoformat(),
                                    "input": input_data,
                                    "result": result
                                }
                                
                                try:
                                    doc_id = self.db.save_document(doc_data)
                                    result['document_id'] = doc_id
                                except Exception as e:
                                    logger.error(f"Error saving to database: {str(e)}")
                                
                                st.session_state.history.append(doc_data)
                                
                                if result.get("success"):
                                    st.success(f"‚úÖ Î¨∏ÏÑú ÏÉùÏÑ± ÏôÑÎ£å! (Î™®Îç∏: {result.get('model_used', 'Unknown')})")
                                    st.balloons()
                                else:
                                    st.error(f"‚ùå Ïò§Î•ò: {result.get('error')}")
                        else:
                            st.warning("ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
                
                with col1_2:
                    if st.button("üé≤ ÏòàÏãú ÏÑ†ÌÉù", use_container_width=True, key="example_selector_btn"):
                        st.session_state.show_example_selector = not st.session_state.get('show_example_selector', False)
                
                # Example selector dialog
                if st.session_state.get('show_example_selector', False):
                    with st.container():
                        st.markdown("### üìö ÏΩîÏä§ÏΩ§ Í∏àÏúµÏòÅÏóÖÎ∂Ä ÏµúÏ†ÅÌôî ÏòàÏãú")
                        
                        # Document type filter
                        example_category = st.selectbox(
                            "Î¨∏ÏÑú Ïú†Ìòï ÏÑ†ÌÉù",
                            ["Ï†ÑÏ≤¥"] + [
                                "email (Ïù¥Î©îÏùº)",
                                "proposal (Ï†úÏïàÏÑú)",
                                "report (Î≥¥Í≥†ÏÑú)",
                                "official (Í≥µÏãùÎ¨∏ÏÑú)"
                            ],
                            key="example_category_select"
                        )
                        
                        # Get examples based on category
                        if example_category == "Ï†ÑÏ≤¥":
                            examples = []
                            for cat in ['email', 'proposal', 'report', 'official']:
                                examples.extend(self.example_templates.get_examples_by_category(cat))
                        else:
                            cat_key = example_category.split(' ')[0]
                            examples = self.example_templates.get_examples_by_category(cat_key)
                        
                        # Display examples in a grid
                        if examples:
                            for idx, example in enumerate(examples):
                                with st.expander(f"{example['title']} - {example['category']}", expanded=False):
                                    st.write(example.get('requirements', '')[:200] + "...")
                                    
                                    # Advanced options
                                    col_opt1, col_opt2, col_opt3 = st.columns(3)
                                    with col_opt1:
                                        use_c7 = st.checkbox(
                                            "Context7 Ìå®ÌÑ¥",
                                            value=True,
                                            key=f"c7_{idx}",
                                            help="Context7 Î¨∏ÏÑú Íµ¨Ï°∞ Ìå®ÌÑ¥ Ï†ÅÏö©"
                                        )
                                    with col_opt2:
                                        use_seq = st.checkbox(
                                            "Sequential",
                                            value=True,
                                            key=f"seq_{idx}",
                                            help="Sequential Thinking Ï†ÅÏö©"
                                        )
                                    with col_opt3:
                                        length_pref = st.select_slider(
                                            "Í∏∏Ïù¥",
                                            options=["short", "medium", "long"],
                                            value=example.get('length', 'medium'),
                                            key=f"length_{idx}"
                                        )
                                    
                                    if st.button(
                                        "‚úÖ Ïù¥ ÏòàÏãú ÏÇ¨Ïö©",
                                        key=f"use_example_{idx}",
                                        use_container_width=True,
                                        type="primary"
                                    ):
                                        # Generate advanced prompt
                                        advanced_prompt = self.example_templates.generate_advanced_prompt(
                                            example,
                                            use_context7=use_c7,
                                            use_sequential=use_seq,
                                            length_preference=length_pref
                                        )
                                        
                                        # Set the values
                                        st.session_state.example_requirements = advanced_prompt
                                        st.session_state.example_recipient = example.get('recipient', '')
                                        st.session_state.example_subject = example.get('subject', '')
                                        st.session_state.example_context = example.get('additional_context', '')
                                        st.session_state.example_tone = example.get('tone', 'professional')
                                        st.session_state.show_example_selector = False
                                        st.rerun()
                        
                        # Close button
                        if st.button("‚ùå Îã´Í∏∞", use_container_width=True):
                            st.session_state.show_example_selector = False
                            st.rerun()
            
            with col2:
                st.markdown("### üìÑ ÏÉùÏÑ±Îêú Î¨∏ÏÑú")
                
                if st.session_state.current_result and st.session_state.current_result.get("success"):
                    result = st.session_state.current_result
                    
                    # Model info badge
                    provider = result.get('provider', 'Unknown')
                    model = result.get('model_used', 'Unknown')
                    
                    col2_1, col2_2 = st.columns([2, 1])
                    with col2_1:
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            <strong>ü§ñ {provider}</strong> | {model}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2_2:
                        quality_score = result.get('quality_score', 0)
                        if quality_score >= 0.9:
                            quality_badge = "üèÜ Ïö∞Ïàò"
                            quality_color = "#00b894"
                        elif quality_score >= 0.8:
                            quality_badge = "‚úÖ ÏñëÌò∏"
                            quality_color = "#fdcb6e"
                        else:
                            quality_badge = "‚ö†Ô∏è Í∞úÏÑ†ÌïÑÏöî"
                            quality_color = "#d63031"
                        
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: {quality_color}; 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            {quality_badge} {quality_score:.1%}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Document content
                    st.text_area(
                        "ÏµúÏ¢Ö Î¨∏ÏÑú",
                        value=result.get("final_document", ""),
                        height=350,
                        label_visibility="collapsed"
                    )
                    
                    # Metrics
                    col2_1, col2_2, col2_3 = st.columns(3)
                    with col2_1:
                        st.metric("‚è±Ô∏è Ï≤òÎ¶¨ ÏãúÍ∞Ñ", f"{result.get('total_time', 0):.1f}Ï¥à")
                    with col2_2:
                        doc_length = len(result.get("final_document", ""))
                        st.metric("üìè Î¨∏ÏÑú Í∏∏Ïù¥", f"{doc_length:,}Ïûê")
                    with col2_3:
                        word_count = len(result.get("final_document", "").split())
                        st.metric("üìù Îã®Ïñ¥ Ïàò", f"{word_count:,}Í∞ú")
                    
                    # Download button
                    st.download_button(
                        label="üì• Î¨∏ÏÑú Îã§Ïö¥Î°úÎìú",
                        data=result["final_document"],
                        file_name=f"document_{provider}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                else:
                    st.info("üí° ÏôºÏ™ΩÏóêÏÑú ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•ÌïòÍ≥† 'Î¨∏ÏÑú ÏÉùÏÑ±' Î≤ÑÌäºÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî.")
                    
                    # Show example if available
                    if hasattr(st.session_state, 'example_text'):
                        st.markdown("#### ÏòàÏãú ÏöîÍµ¨ÏÇ¨Ìï≠:")
                        st.info(st.session_state.example_text)
        
        with tab2:
            st.markdown("### üîÑ Ï¥àÏïà vs ÏµúÏ¢Ö Î¨∏ÏÑú ÎπÑÍµê")
            
            if st.session_state.draft_document and st.session_state.current_result:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### üìù Ï¥àÏïà")
                    st.text_area(
                        "Ï¥àÏïà Î¨∏ÏÑú",
                        value=st.session_state.draft_document,
                        height=400,
                        label_visibility="collapsed",
                        key="draft_compare"
                    )
                    
                    # Draft metrics
                    draft_terms = validate_financial_terms(st.session_state.draft_document)
                    draft_compliance = check_compliance(st.session_state.draft_document, "email")
                    draft_score = calculate_quality_score(st.session_state.draft_document, draft_terms, draft_compliance)
                    
                    st.metric("Ï¥àÏïà ÌíàÏßà", f"{draft_score:.1%}")
                    st.metric("Ï¥àÏïà Í∏∏Ïù¥", f"{len(st.session_state.draft_document):,}Ïûê")
                
                with col2:
                    st.markdown("#### ‚ú® ÏµúÏ¢Ö Î¨∏ÏÑú")
                    final_doc = st.session_state.current_result.get('final_document', '')
                    st.text_area(
                        "ÏµúÏ¢Ö Î¨∏ÏÑú",
                        value=final_doc,
                        height=400,
                        label_visibility="collapsed",
                        key="final_compare"
                    )
                    
                    # Final metrics
                    final_score = st.session_state.current_result.get('quality_score', 0)
                    st.metric("ÏµúÏ¢Ö ÌíàÏßà", f"{final_score:.1%}")
                    st.metric("ÏµúÏ¢Ö Í∏∏Ïù¥", f"{len(final_doc):,}Ïûê")
                
                # Improvement analysis
                st.markdown("#### üìà Í∞úÏÑ† Î∂ÑÏÑù")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    improvement = (final_score - draft_score) * 100
                    if improvement > 0:
                        st.success(f"ÌíàÏßà Í∞úÏÑ†: +{improvement:.1f}%")
                    elif improvement < 0:
                        st.error(f"ÌíàÏßà ÌïòÎùΩ: {improvement:.1f}%")
                    else:
                        st.info("ÌíàÏßà ÎèôÏùº")
                
                with col2:
                    length_change = len(final_doc) - len(st.session_state.draft_document)
                    if length_change > 0:
                        st.info(f"Í∏∏Ïù¥ Ï¶ùÍ∞Ä: +{length_change:,}Ïûê")
                    elif length_change < 0:
                        st.info(f"Í∏∏Ïù¥ Í∞êÏÜå: {length_change:,}Ïûê")
                    else:
                        st.info("Í∏∏Ïù¥ ÎèôÏùº")
                
                with col3:
                    if st.button("‚ôªÔ∏è Î¨∏ÏÑú Ïû¨Ï†ïÏ†ú", use_container_width=True):
                        # Refine document again
                        refinement_prompt = f"Îã§Ïùå Î¨∏ÏÑúÎ•º Îçî Í∞úÏÑ†Ìï¥Ï£ºÏÑ∏Ïöî:\n\n{final_doc}"
                        input_data = st.session_state.current_result.get('input', {})
                        input_data['requirements'] = refinement_prompt
                        
                        with st.spinner("Î¨∏ÏÑúÎ•º Ïû¨Ï†ïÏ†úÌïòÎäî Ï§ë..."):
                            refined_result = self.process_document(input_data, is_refinement=True)
                            if refined_result.get('success'):
                                st.session_state.current_result = refined_result
                                st.session_state.refinement_history.append({
                                    'version': f"Ï†ïÏ†ú {len(st.session_state.refinement_history)}",
                                    'content': refined_result.get('final_document', ''),
                                    'timestamp': datetime.now().isoformat(),
                                    'model': f"{refined_result.get('provider')} - {refined_result.get('model_used')}"
                                })
                                st.success("Î¨∏ÏÑúÍ∞Ä Ïû¨Ï†ïÏ†úÎêòÏóàÏäµÎãàÎã§!")
                                st.rerun()
                
                # Refinement history
                if len(st.session_state.refinement_history) > 1:
                    st.markdown("#### üìö Ï†ïÏ†ú Ïù¥Î†•")
                    for idx, version in enumerate(st.session_state.refinement_history):
                        with st.expander(f"{version['version']} - {version['model']}"):
                            st.text_area(
                                f"Î≤ÑÏ†Ñ {idx}",
                                value=version['content'][:500] + "...",
                                height=150,
                                label_visibility="collapsed",
                                key=f"version_{idx}"
                            )
            else:
                st.info("Î®ºÏ†Ä Î¨∏ÏÑúÎ•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî. Î¨∏ÏÑú ÏûëÏÑ± ÌÉ≠ÏóêÏÑú ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•ÌïòÍ≥† ÏÉùÏÑ± Î≤ÑÌäºÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî.")
        
        with tab3:
            st.markdown("### üîÄ Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ ÏÉÅÏÑ∏ Î∂ÑÏÑù")
            
            if st.session_state.draft_document and st.session_state.current_result:
                # View mode selector
                view_mode = st.radio(
                    "Î∂ÑÏÑù Î™®Îìú",
                    ["Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ ÏöîÏïΩ", "ÎùºÏù∏Î≥Ñ ÎπÑÍµê", "Îã®Ïñ¥Î≥Ñ ÎπÑÍµê", "ÏàòÏ†ï Ïù¥Ïú† Î∂ÑÏÑù"],
                    horizontal=True
                )
                
                draft_doc = st.session_state.draft_document
                final_doc = st.session_state.current_result.get('final_document', '')
                
                if view_mode == "Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ ÏöîÏïΩ":
                    # Statistics
                    stats = get_change_statistics(draft_doc, final_doc)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric(
                            "Î¨∏ÏÑú Ïú†ÏÇ¨ÎèÑ",
                            f"{stats['similarity']:.1f}%",
                            help="Ï¥àÏïàÍ≥º ÏµúÏ¢ÖÎ≥∏Ïùò ÌÖçÏä§Ìä∏ Ïú†ÏÇ¨ÎèÑ"
                        )
                    with col2:
                        st.metric(
                            "Í∏∏Ïù¥ Î≥ÄÌôî",
                            f"{stats['length_change']:+,}Ïûê",
                            f"{stats['length_change_percent']:+.1f}%"
                        )
                    with col3:
                        st.metric(
                            "Îã®Ïñ¥ Ïàò Î≥ÄÌôî",
                            f"{stats['word_change']:+,}Í∞ú",
                            help="Ï¥ù Îã®Ïñ¥ ÏàòÏùò Î≥ÄÌôî"
                        )
                    with col4:
                        st.metric(
                            "Î¨∏Ïû• Ïàò Î≥ÄÌôî",
                            f"{stats['sentences_final'] - stats['sentences_original']:+,}Í∞ú",
                            help="Î¨∏Ïû• Í∞úÏàòÏùò Î≥ÄÌôî"
                        )
                    
                    # Modification summary from critique history
                    if st.session_state.critique_history:
                        st.markdown("#### üìù Ï£ºÏöî ÏàòÏ†ï ÏÇ¨Ìï≠")
                        
                        all_modifications = []
                        for critique_item in st.session_state.critique_history:
                            critique_text = critique_item.get('critique', '')
                            if critique_text:
                                mods = extract_modifications(critique_text)
                                all_modifications.extend(mods)
                        
                        if all_modifications:
                            summary_html = create_modification_summary(all_modifications)
                            st.markdown(summary_html, unsafe_allow_html=True)
                        else:
                            st.info("ÏàòÏ†ï ÏÇ¨Ìï≠ÏùÑ ÏûêÎèôÏúºÎ°ú Ï∂îÏ∂úÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
                    
                    # Quality improvement timeline
                    if st.session_state.critique_history:
                        st.markdown("#### üìà ÌíàÏßà Í∞úÏÑ† Ï∂îÏù¥")
                        
                        iterations = []
                        scores = []
                        for critique_item in st.session_state.critique_history:
                            iterations.append(f"Î∞òÎ≥µ {critique_item['iteration']}")
                            scores.append(critique_item.get('quality_score', 0) * 100)
                        
                        # Simple chart using columns
                        chart_cols = st.columns(len(iterations))
                        for i, (iter_name, score) in enumerate(zip(iterations, scores)):
                            with chart_cols[i]:
                                st.metric(iter_name, f"{score:.0f}%")
                
                elif view_mode == "ÎùºÏù∏Î≥Ñ ÎπÑÍµê":
                    st.markdown("#### üìÑ ÎùºÏù∏Î≥Ñ Ï∞®Ïù¥Ï†ê")
                    
                    # Create line diff
                    diff_html = create_diff_html(draft_doc, final_doc, "Ï¥àÏïà", "ÏµúÏ¢Ö")
                    st.markdown(diff_html, unsafe_allow_html=True)
                    
                    # Download diff as text
                    diff_text = f"=== Ï¥àÏïà ===\n{draft_doc}\n\n=== ÏµúÏ¢Ö ===\n{final_doc}"
                    st.download_button(
                        "üì• ÎπÑÍµê Í≤∞Í≥º Îã§Ïö¥Î°úÎìú",
                        diff_text,
                        file_name=f"diff_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                elif view_mode == "Îã®Ïñ¥Î≥Ñ ÎπÑÍµê":
                    st.markdown("#### üìù Îã®Ïñ¥ ÏàòÏ§Ä Î≥ÄÍ≤ΩÏÇ¨Ìï≠")
                    
                    word_diff_html, word_stats = create_word_diff(draft_doc, final_doc)
                    
                    # Show statistics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Ï∂îÍ∞ÄÎêú Îã®Ïñ¥", word_stats['added'])
                    with col2:
                        st.metric("ÏÇ≠Ï†úÎêú Îã®Ïñ¥", word_stats['removed'])
                    with col3:
                        st.metric("Ï¥ù Î≥ÄÍ≤Ω", word_stats['total_changes'])
                    
                    # Show word diff
                    st.markdown(
                        f'<div style="background: white; padding: 1rem; border-radius: 8px; line-height: 1.8;">{word_diff_html}</div>',
                        unsafe_allow_html=True
                    )
                
                elif view_mode == "ÏàòÏ†ï Ïù¥Ïú† Î∂ÑÏÑù":
                    st.markdown("#### üîç ÏàòÏ†ï Ïù¥Ïú† Î∞è Í∑ºÍ±∞")
                    
                    if st.session_state.critique_history:
                        for i, critique_item in enumerate(st.session_state.critique_history, 1):
                            with st.expander(f"Î∞òÎ≥µ {i} - ÌíàÏßà Ï†êÏàò: {critique_item.get('quality_score', 0):.1%}"):
                                critique_text = critique_item.get('critique', '')
                                
                                # Display issues
                                issues = critique_item.get('issues', [])
                                if issues:
                                    st.markdown("**Î∞úÍ≤¨Îêú Î¨∏Ï†úÏ†ê:**")
                                    for issue in issues:
                                        st.markdown(f"- ‚ö†Ô∏è {issue}")
                                
                                # Display suggestions
                                suggestions = critique_item.get('suggestions', [])
                                if suggestions:
                                    st.markdown("**Í∞úÏÑ† Ï†úÏïà:**")
                                    for suggestion in suggestions:
                                        st.markdown(f"- üí° {suggestion}")
                                
                                # Display full critique
                                if critique_text:
                                    st.markdown("**ÏÉÅÏÑ∏ ÎπÑÌèâ:**")
                                    st.text_area(
                                        "ÎπÑÌèâ ÎÇ¥Ïö©",
                                        value=critique_text,
                                        height=200,
                                        label_visibility="collapsed",
                                        key=f"critique_{i}"
                                    )
                    else:
                        st.info("LoopAgentÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Î¨∏ÏÑúÎ•º ÏÉùÏÑ±ÌïòÎ©¥ ÏÉÅÏÑ∏Ìïú ÏàòÏ†ï Ïù¥Ïú†Î•º ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
                
                # Export options
                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üìä Î∂ÑÏÑù Î≥¥Í≥†ÏÑú ÏÉùÏÑ±", use_container_width=True):
                        # Generate comprehensive report
                        report = f"""# Î¨∏ÏÑú Í∞úÏÑ† Î∂ÑÏÑù Î≥¥Í≥†ÏÑú
ÏÉùÏÑ±Ïùº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## 1. Í∞úÏöî
- Ï¥àÏïà Í∏∏Ïù¥: {len(draft_doc):,}Ïûê
- ÏµúÏ¢Ö Í∏∏Ïù¥: {len(final_doc):,}Ïûê
- Î≥ÄÍ≤ΩÎ•†: {((len(final_doc) - len(draft_doc)) / len(draft_doc) * 100):.1f}%
- Î¨∏ÏÑú Ïú†ÏÇ¨ÎèÑ: {calculate_similarity(draft_doc, final_doc) * 100:.1f}%

## 2. Ï¥àÏïà
{draft_doc}

## 3. ÏµúÏ¢ÖÎ≥∏
{final_doc}

## 4. Ï£ºÏöî Î≥ÄÍ≤Ω ÏÇ¨Ìï≠
{' '.join([f"- {mod['description']}" for critique in st.session_state.critique_history for mod in extract_modifications(critique.get('critique', ''))][:5])}
"""
                        st.download_button(
                            "üì• Î≥¥Í≥†ÏÑú Îã§Ïö¥Î°úÎìú",
                            report,
                            file_name=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
                
                with col2:
                    if st.button("üîÑ Ïû¨Î∂ÑÏÑù", use_container_width=True):
                        st.rerun()
            
            else:
                st.info("Î¨∏ÏÑúÎ•º ÏÉùÏÑ±Ìïú ÌõÑ Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ Î∂ÑÏÑùÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
        
        with tab4:
            st.markdown("### üîç Ïó¨Îü¨ Î™®Îç∏ ÎπÑÍµê")
            st.info("ÎèôÏùºÌïú ÏöîÍµ¨ÏÇ¨Ìï≠ÏúºÎ°ú Ïó¨Îü¨ AI Î™®Îç∏Ïùò Í≤∞Í≥ºÎ•º ÎπÑÍµêÌï¥Î≥¥ÏÑ∏Ïöî.")
            
            compare_requirements = st.text_area(
                "ÎπÑÍµêÌï† Î¨∏ÏÑú ÏöîÍµ¨ÏÇ¨Ìï≠",
                placeholder="Î™®Îì† Î™®Îç∏ÏóêÏÑú ÌÖåÏä§Ìä∏Ìï† ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî...",
                height=150,
                key="compare_requirements"
            )
            
            # Model selection for comparison
            st.markdown("#### ÎπÑÍµêÌï† Î™®Îç∏ ÏÑ†ÌÉù")
            col1, col2, col3 = st.columns(3)
            
            compare_models = []
            with col1:
                if config.ANTHROPIC_API_KEY and st.checkbox("Anthropic Claude", value=True):
                    compare_models.append("Anthropic")
            with col2:
                if config.OPENAI_API_KEY and st.checkbox("OpenAI GPT", value=True):
                    compare_models.append("OpenAI")
            with col3:
                if config.GOOGLE_API_KEY and st.checkbox("Google Gemini", value=True):
                    compare_models.append("Google")
            
            if st.button("üî¨ ÏÑ†ÌÉùÌïú Î™®Îç∏Î°ú ÎπÑÍµê ÏÉùÏÑ±", type="primary", use_container_width=True):
                if compare_requirements and compare_models:
                    if not self.multi_model_agent:
                        agent_config = config.get_agent_config()
                        self.multi_model_agent = MultiModelAgent(agent_config)
                    
                    # Create input data
                    input_data = {
                        "document_type": doc_type,
                        "requirements": compare_requirements,
                        "tone": tone,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    }
                    
                    prompt = self._create_prompt(input_data)
                    
                    # Progress bar for comparison
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = {}
                    for idx, provider in enumerate(compare_models):
                        status_text.text(f"ü§ñ {provider} Î™®Îç∏Î°ú ÏÉùÏÑ± Ï§ë...")
                        progress_bar.progress((idx + 1) / len(compare_models))
                        
                        try:
                            response = self.multi_model_agent.generate(prompt, provider=provider)
                            results[provider] = response
                        except Exception as e:
                            st.error(f"{provider} Ïò§Î•ò: {str(e)}")
                    
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Display comparison results
                    if results:
                        st.markdown("#### üìä ÎπÑÍµê Í≤∞Í≥º")
                        
                        # Create columns for side-by-side comparison
                        cols = st.columns(len(results))
                        
                        for idx, (provider, response) in enumerate(results.items()):
                            with cols[idx]:
                                st.markdown(f"##### {provider}")
                                
                                # Calculate quality score
                                term_validation = validate_financial_terms(response.content)
                                compliance_check = check_compliance(response.content, doc_type)
                                quality_score = calculate_quality_score(response.content, term_validation, compliance_check)
                                
                                # Quality badge
                                if quality_score >= 0.9:
                                    st.success(f"ÌíàÏßà: {quality_score:.1%}")
                                elif quality_score >= 0.8:
                                    st.warning(f"ÌíàÏßà: {quality_score:.1%}")
                                else:
                                    st.error(f"ÌíàÏßà: {quality_score:.1%}")
                                
                                st.text_area(
                                    f"{provider} Í≤∞Í≥º",
                                    value=response.content,
                                    height=400,
                                    label_visibility="collapsed",
                                    key=f"compare_{provider}"
                                )
                                
                                st.metric("Î™®Îç∏", response.model_used)
                                st.metric("Î¨∏Ïûê Ïàò", f"{len(response.content):,}")
                else:
                    if not compare_requirements:
                        st.warning("ÎπÑÍµêÌï† ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
                    if not compare_models:
                        st.warning("ÎπÑÍµêÌï† Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.")
        
        with tab4:
            st.markdown("### üìä ÌÜµÍ≥Ñ Î∞è Î∂ÑÏÑù")
            
            # Statistics period selector
            col1, col2 = st.columns([3, 1])
            with col1:
                stat_period = st.selectbox(
                    "ÌÜµÍ≥Ñ Í∏∞Í∞Ñ",
                    ["Ïò§Îäò", "ÏßÄÎÇú 7Ïùº", "ÏßÄÎÇú 30Ïùº", "Ï†ÑÏ≤¥"],
                    index=2
                )
            with col2:
                if st.button("üîÑ ÏÉàÎ°úÍ≥†Ïπ®", use_container_width=True):
                    self._load_statistics_from_db()
                    st.rerun()
            
            # Calculate period days
            if stat_period == "Ïò§Îäò":
                days = 1
            elif stat_period == "ÏßÄÎÇú 7Ïùº":
                days = 7
            elif stat_period == "ÏßÄÎÇú 30Ïùº":
                days = 30
            else:
                days = 365
            
            # Load statistics from database
            try:
                db_stats = self.db.get_statistics(days=days)
            except:
                db_stats = st.session_state.stats
            
            # Overall statistics
            st.markdown("#### üéØ Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "üìÑ Ï¥ù Î¨∏ÏÑú",
                    f"{db_stats.get('total_documents', 0):,}Í∞ú",
                    delta=f"{len(st.session_state.history)}Í∞ú (ÏÑ∏ÏÖò)"
                )
            
            with col2:
                avg_quality = db_stats.get('avg_quality', 0)
                st.metric(
                    "üèÜ ÌèâÍ∑† ÌíàÏßà",
                    f"{avg_quality:.1%}",
                    delta="Ïö∞Ïàò" if avg_quality >= 0.9 else "ÏñëÌò∏"
                )
            
            with col3:
                st.metric(
                    "üîÑ ÌèâÍ∑† Î∞òÎ≥µ",
                    f"{db_stats.get('avg_iterations', 0):.1f}Ìöå"
                )
            
            with col4:
                total_time = db_stats.get('total_time', 0)
                st.metric(
                    "‚è±Ô∏è Ï¥ù ÏÜåÏöîÏãúÍ∞Ñ",
                    f"{total_time:.0f}Ï¥à" if total_time < 3600 else f"{total_time/3600:.1f}ÏãúÍ∞Ñ"
                )
            
            # Provider statistics
            if db_stats.get('by_provider'):
                st.markdown("#### ü§ñ Î™®Îç∏Î≥Ñ ÌÜµÍ≥Ñ")
                provider_cols = st.columns(len(db_stats['by_provider']))
                for idx, (provider, count) in enumerate(db_stats['by_provider'].items()):
                    with provider_cols[idx]:
                        st.metric(provider, f"{count}Í∞ú")
            
            # Document type statistics
            if db_stats.get('by_document_type'):
                st.markdown("#### üìÅ Î¨∏ÏÑú Ïú†ÌòïÎ≥Ñ ÌÜµÍ≥Ñ")
                doc_type_cols = st.columns(min(len(db_stats['by_document_type']), 5))
                for idx, (doc_type, count) in enumerate(list(db_stats['by_document_type'].items())[:5]):
                    with doc_type_cols[idx % len(doc_type_cols)]:
                        st.metric(doc_type, f"{count}Í∞ú")
            
            # Current document analysis (if available)
            if st.session_state.current_result and st.session_state.current_result.get("success"):
                st.markdown("---")
                st.markdown("### üìÑ ÌòÑÏû¨ Î¨∏ÏÑú Î∂ÑÏÑù")
                result = st.session_state.current_result
                
                # Create beautiful analysis cards
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### üéØ ÌíàÏßà ÏßÄÌëú")
                    
                    validation = result.get('validation', {})
                    
                    # Quality score visualization
                    quality_score = result.get('quality_score', 0)
                    st.progress(quality_score)
                    
                    # Detailed metrics
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>ÏÉÅÏÑ∏ ÌèâÍ∞Ä</h4>
                        <ul>
                            <li>Ï†ÑÏ≤¥ ÌíàÏßà: <strong>{quality_score:.1%}</strong></li>
                            <li>Ïö©Ïñ¥ Ï†ïÌôïÎèÑ: <strong>{validation.get('terms', {}).get('score', 0):.1%}</strong></li>
                            <li>Í∑úÏ†ï Ï§ÄÏàò: <strong>{'‚úÖ Ï§ÄÏàò' if validation.get('compliance', {}).get('is_compliant') else '‚ùå ÎØ∏Ï§ÄÏàò'}</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown("#### üìà Î¨∏ÏÑú ÌÜµÍ≥Ñ")
                    
                    doc = result.get('final_document', '')
                    
                    # Text statistics
                    char_count = len(doc)
                    word_count = len(doc.split())
                    sentence_count = doc.count('.') + doc.count('!') + doc.count('?')
                    
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>ÌÖçÏä§Ìä∏ Î∂ÑÏÑù</h4>
                        <ul>
                            <li>Î¨∏Ïûê Ïàò: <strong>{char_count:,}</strong></li>
                            <li>Îã®Ïñ¥ Ïàò: <strong>{word_count:,}</strong></li>
                            <li>Î¨∏Ïû• Ïàò: <strong>{sentence_count:,}</strong></li>
                            <li>ÌèâÍ∑† Î¨∏Ïû• Í∏∏Ïù¥: <strong>{word_count/max(sentence_count, 1):.1f} Îã®Ïñ¥</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Model performance
                st.markdown("#### ‚ö° Î™®Îç∏ ÏÑ±Îä•")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ü§ñ ÏÇ¨Ïö© Î™®Îç∏", result.get('provider', '-'))
                with col2:
                    st.metric("‚è±Ô∏è Ï≤òÎ¶¨ ÏãúÍ∞Ñ", f"{result.get('total_time', 0):.1f}Ï¥à")
                with col3:
                    st.metric("üîÑ Î∞òÎ≥µ ÌöüÏàò", result.get('iterations', 1))
            else:
                st.info("Î®ºÏ†Ä Î¨∏ÏÑúÎ•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.")
        
        with tab5:
            if st.session_state.history:
                st.markdown("### üìö Î¨∏ÏÑú ÏÉùÏÑ± Ïù¥Î†•")
                
                # History filter
                col1, col2 = st.columns([2, 1])
                with col1:
                    search_term = st.text_input("üîç Í≤ÄÏÉâ", placeholder="Ïù¥Î†•ÏóêÏÑú Í≤ÄÏÉâ...")
                with col2:
                    sort_order = st.selectbox("Ï†ïÎ†¨", ["ÏµúÏã†Ïàú", "Ïò§ÎûòÎêúÏàú", "ÌíàÏßàÏàú"])
                
                # Sort history
                sorted_history = st.session_state.history.copy()
                if sort_order == "ÏµúÏã†Ïàú":
                    sorted_history.reverse()
                elif sort_order == "ÌíàÏßàÏàú":
                    sorted_history.sort(key=lambda x: x['result'].get('quality_score', 0), reverse=True)
                
                # Filter history
                if search_term:
                    sorted_history = [
                        item for item in sorted_history
                        if search_term.lower() in str(item).lower()
                    ]
                
                # Display history
                for idx, item in enumerate(sorted_history, 1):
                    timestamp = datetime.fromisoformat(item['timestamp'])
                    result = item['result']
                    
                    if result.get('success'):
                        with st.expander(
                            f"üìÑ Î¨∏ÏÑú #{idx} | "
                            f"{timestamp.strftime('%Y-%m-%d %H:%M')} | "
                            f"{result.get('provider', 'Unknown')} | "
                            f"ÌíàÏßà: {result.get('quality_score', 0):.1%}"
                        ):
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.markdown("**üìã ÏöîÏ≤≠ Ï†ïÎ≥¥**")
                                st.write(f"Î¨∏ÏÑú Ïú†Ìòï: {item['input']['document_type']}")
                                st.write(f"ÌÜ§: {item['input']['tone']}")
                                st.write(f"Î™®Îç∏: {result.get('model_used', '-')}")
                                st.write(f"ÌíàÏßà: {result.get('quality_score', 0):.1%}")
                                st.write(f"ÏãúÍ∞Ñ: {result.get('total_time', 0):.1f}Ï¥à")
                            
                            with col2:
                                st.markdown("**üìÑ ÏÉùÏÑ±Îêú Î¨∏ÏÑú**")
                                st.text_area(
                                    "Î¨∏ÏÑú ÎÇ¥Ïö©",
                                    value=result.get('final_document', ''),
                                    height=200,
                                    label_visibility="collapsed",
                                    key=f"history_{idx}"
                                )
                                
                                col1_btn, col2_btn = st.columns(2)
                                with col1_btn:
                                    st.download_button(
                                        label="üì• Îã§Ïö¥Î°úÎìú",
                                        data=result.get('final_document', ''),
                                        file_name=f"history_{idx}_{timestamp.strftime('%Y%m%d_%H%M%S')}.txt",
                                        mime="text/plain",
                                        key=f"download_{idx}",
                                        use_container_width=True
                                    )
                                with col2_btn:
                                    if result.get('document_id'):
                                        st.caption(f"üìå DB ID: {result['document_id']}")
            else:
                st.info("ÏïÑÏßÅ ÏÉùÏÑ±Îêú Î¨∏ÏÑúÍ∞Ä ÏóÜÏäµÎãàÎã§. Î¨∏ÏÑúÎ•º ÏÉùÏÑ±ÌïòÎ©¥ Ïó¨Í∏∞Ïóê Ïù¥Î†•Ïù¥ ÌëúÏãúÎê©ÎãàÎã§.")
            
            # Export options
            st.markdown("---")
            st.markdown("### üíæ Îç∞Ïù¥ÌÑ∞ ÎÇ¥Î≥¥ÎÇ¥Í∏∞")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("üìä JSONÏúºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞", use_container_width=True):
                    try:
                        export_data = self.db.export_data("json")
                        st.download_button(
                            "üì• JSON Îã§Ïö¥Î°úÎìú",
                            data=export_data,
                            file_name=f"adk_writer_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"Export Ïò§Î•ò: {str(e)}")
            
            with col2:
                if st.button("üìã CSVÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞", use_container_width=True):
                    try:
                        export_data = self.db.export_data("csv")
                        st.download_button(
                            "üì• CSV Îã§Ïö¥Î°úÎìú",
                            data=export_data,
                            file_name=f"adk_writer_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"Export Ïò§Î•ò: {str(e)}")
            
            with col3:
                # Database statistics
                try:
                    db_stats = self.db.get_statistics(days=30)
                    st.metric("üìä Ï†ÑÏ≤¥ Î¨∏ÏÑú", f"{db_stats['total_documents']:,}Í∞ú")
                except:
                    st.metric("üìä ÏÑ∏ÏÖò Î¨∏ÏÑú", f"{len(st.session_state.history)}Í∞ú")


def main():
    """Main entry point"""
    app = MultiModelFinancialWritingApp()
    app.run()


if __name__ == "__main__":
    main()
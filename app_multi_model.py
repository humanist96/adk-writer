"""
Multi-Model AI Financial Writer Pro - Streamlit Cloud Version
Supports Anthropic Claude, OpenAI GPT, and Google Gemini
"""

import streamlit as st
from typing import Dict, Any, Optional
import json
from datetime import datetime
from pathlib import Path
import time
from loguru import logger

# Page configuration
st.set_page_config(
    page_title="AI Financial Writer Pro - Multi Model",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Try cloud config first, fallback to local
try:
    from src.config_cloud import config
except:
    from src.config import config

from src.agents.multi_model_agents import (
    ModelFactory,
    MultiModelAgent,
    MultiModelAgentResponse
)
from src.agents.loop_agent import LoopAgent
from src.tools.custom_tools import (
    validate_financial_terms,
    check_compliance,
    calculate_quality_score
)
from src.utils.diff_utils import (
    create_diff_html,
    create_word_diff,
    extract_modifications,
    create_modification_summary,
    get_change_statistics,
    calculate_similarity
)
from src.database import get_db_manager
from src.utils.example_templates import ExampleTemplates

# Custom CSS for modern UI
st.markdown("""
<style>
    /* Main App Styling */
    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    /* Header Styling */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2.5rem;
        border-radius: 20px;
        margin-bottom: 2rem;
        color: white;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        animation: slideDown 0.5s ease-out;
    }
    
    @keyframes slideDown {
        from {
            opacity: 0;
            transform: translateY(-20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Card Styling */
    .stat-card {
        background: white;
        border-radius: 16px;
        padding: 1.5rem;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
        margin-bottom: 1rem;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        border: 1px solid rgba(255, 255, 255, 0.8);
    }
    
    .stat-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }
    
    /* Model Selection Cards */
    .model-selector {
        background: white;
        border-radius: 12px;
        padding: 1rem;
        margin: 0.5rem 0;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .model-selector:hover {
        border-color: #667eea;
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
    }
    
    .model-selector.selected {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: #667eea;
    }
    
    /* Provider Badges */
    .provider-badge {
        display: inline-block;
        padding: 0.4rem 1rem;
        border-radius: 25px;
        font-size: 0.875rem;
        font-weight: 600;
        margin: 0.25rem;
        transition: all 0.3s ease;
    }
    
    .provider-badge:hover {
        transform: scale(1.05);
    }
    
    .anthropic-badge {
        background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);
        color: white;
    }
    
    .openai-badge {
        background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
        color: white;
    }
    
    .google-badge {
        background: linear-gradient(135deg, #4285f4 0%, #34a853 100%);
        color: white;
    }
    
    /* Metric Values */
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: pulse 2s ease-in-out infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.8; }
    }
    
    /* Button Styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.8rem 2rem;
        border-radius: 12px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* Sidebar Styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Tab Styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 12px;
        padding: 0.5rem 1.5rem;
        background: white;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: transparent;
    }
    
    /* Success/Error Messages */
    .stSuccess {
        background: linear-gradient(135deg, #00b894 0%, #00cec9 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    .stError {
        background: linear-gradient(135deg, #ff7675 0%, #d63031 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    /* Text Area Styling */
    .stTextArea textarea {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTextArea textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Select Box Styling */
    .stSelectbox > div > div {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
</style>
""", unsafe_allow_html=True)

class MultiModelFinancialWritingApp:
    """Multi-Model Financial Writing AI Application"""
    
    def __init__(self):
        self.config = config
        self.multi_model_agent = None
        self.db = get_db_manager()  # Initialize database manager
        self.example_templates = ExampleTemplates()  # Initialize example templates
        self._initialize_session_state()
        self._load_statistics_from_db()
    
    def _initialize_session_state(self):
        """Initialize session state variables"""
        if 'history' not in st.session_state:
            st.session_state.history = []
        if 'current_result' not in st.session_state:
            st.session_state.current_result = None
        if 'stats' not in st.session_state:
            st.session_state.stats = {
                'total_documents': 0,
                'avg_quality': 0,
                'avg_iterations': 0,
                'total_time': 0,
                'models_used': {}
            }
        if 'selected_provider' not in st.session_state:
            st.session_state.selected_provider = config.DEFAULT_PROVIDER
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = config.ANTHROPIC_MODEL if config.DEFAULT_PROVIDER == "Anthropic" else None
        if 'draft_document' not in st.session_state:
            st.session_state.draft_document = None
        if 'refinement_history' not in st.session_state:
            st.session_state.refinement_history = []
        if 'critique_history' not in st.session_state:
            st.session_state.critique_history = []
    
    def _load_statistics_from_db(self):
        """Load statistics from database"""
        try:
            db_stats = self.db.get_statistics(days=30)
            st.session_state.stats = {
                'total_documents': db_stats['total_documents'],
                'avg_quality': db_stats['avg_quality'],
                'avg_iterations': db_stats['avg_iterations'],
                'total_time': db_stats['total_time'],
                'models_used': db_stats.get('by_provider', {}),
                'daily_stats': db_stats.get('daily_stats', []),
                'by_document_type': db_stats.get('by_document_type', {})
            }
        except Exception as e:
            logger.warning(f"Could not load statistics from database: {str(e)}")
    
    def render_header(self):
        """Render animated header"""
        st.markdown("""
        <div class="main-header">
            <h1 style="margin: 0; font-size: 2.8rem; font-weight: 800;">
                ğŸ¤– AI Financial Writer Pro
            </h1>
            <p style="margin-top: 0.8rem; font-size: 1.2rem; opacity: 0.95;">
                ì°¨ì„¸ëŒ€ ê¸ˆìœµ ë¬¸ì„œ ì‘ì„± AI í”Œë«í¼
            </p>
            <div style="margin-top: 1rem;">
                <span class="provider-badge anthropic-badge">Anthropic Claude</span>
                <span class="provider-badge openai-badge">OpenAI GPT</span>
                <span class="provider-badge google-badge">Google Gemini</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar_model_selector(self):
        """Render model selection in sidebar"""
        st.sidebar.markdown("## ğŸ¤– AI ëª¨ë¸ ì„¤ì •")
        
        available_models = ModelFactory.get_available_models()
        providers_available = []
        
        # Check available providers
        if config.ANTHROPIC_API_KEY:
            providers_available.append("Anthropic")
        if config.OPENAI_API_KEY:
            providers_available.append("OpenAI")
        if config.GOOGLE_API_KEY:
            providers_available.append("Google")
        
        if not providers_available:
            st.sidebar.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return providers_available
        
        # Provider selection
        st.sidebar.markdown("### ğŸ“¦ AI ì œê³µì")
        selected_provider = st.sidebar.radio(
            "ì œê³µì ì„ íƒ",
            options=providers_available,
            index=providers_available.index(st.session_state.selected_provider) if st.session_state.selected_provider in providers_available else 0,
            label_visibility="collapsed",
            help="ì‚¬ìš©í•  AI ì œê³µìë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if selected_provider != st.session_state.selected_provider:
            st.session_state.selected_provider = selected_provider
            st.session_state.selected_model = None
            st.rerun()
        
        # Model selection for current provider
        if selected_provider in available_models:
            st.sidebar.markdown("### ğŸ¯ ëª¨ë¸ ì„ íƒ")
            
            models = available_models[selected_provider]
            model_options = list(models.keys())
            model_labels = list(models.values())
            
            # Set default model index
            if st.session_state.selected_model and st.session_state.selected_model in model_options:
                default_index = model_options.index(st.session_state.selected_model)
            else:
                default_index = 0
                st.session_state.selected_model = model_options[0]
            
            selected_model = st.sidebar.selectbox(
                "ëª¨ë¸",
                options=model_options,
                format_func=lambda x: models[x],
                index=default_index,
                label_visibility="collapsed",
                help="ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            if selected_model != st.session_state.selected_model:
                st.session_state.selected_model = selected_model
            
            # Model features
            with st.sidebar.expander("ğŸŒŸ ëª¨ë¸ íŠ¹ì§•", expanded=False):
                if selected_provider == "Anthropic":
                    st.markdown("""
                    **Claude íŠ¹ì§•:**
                    - ğŸ“š ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (200K í† í°)
                    - ğŸ¯ ë†’ì€ ì •í™•ë„ì™€ ì¼ê´€ì„±
                    - ğŸ’¡ ë›°ì–´ë‚œ ì¶”ë¡  ëŠ¥ë ¥
                    - ğŸ”’ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µ
                    """)
                elif selected_provider == "OpenAI":
                    st.markdown("""
                    **GPT íŠ¹ì§•:**
                    - ğŸŒ ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì›
                    - ğŸ¨ ì°½ì˜ì ì¸ ì½˜í…ì¸  ìƒì„±
                    - ğŸ”§ ê°•ë ¥í•œ ì½”ë“œ ìƒì„±
                    - ğŸ“Š ë°ì´í„° ë¶„ì„ ëŠ¥ë ¥
                    """)
                elif selected_provider == "Google":
                    st.markdown("""
                    **Gemini íŠ¹ì§•:**
                    - âš¡ ë¹ ë¥¸ ì‘ë‹µ ì†ë„
                    - ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ ì§€ì›
                    - ğŸ’° ë¹„ìš© íš¨ìœ¨ì 
                    - ğŸ”„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
                    """)
        
        return providers_available
    
    def render_stats(self):
        """Render animated statistics"""
        st.markdown("### ğŸ“Š í†µê³„")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "ğŸ“„ ì´ ìƒì„± ë¬¸ì„œ",
                st.session_state.stats['total_documents'],
                "+1" if st.session_state.stats['total_documents'] > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            quality_value = st.session_state.stats['avg_quality']
            quality_delta = (quality_value - 0.7) * 100 if quality_value > 0 else 0
            st.metric(
                "â­ í‰ê·  í’ˆì§ˆ",
                f"{quality_value:.1%}",
                f"+{quality_delta:.0f}%" if quality_delta > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "ğŸ”„ í‰ê·  ë°˜ë³µ",
                f"{st.session_state.stats['avg_iterations']:.1f}íšŒ",
                None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            if st.session_state.stats['models_used']:
                most_used = max(st.session_state.stats['models_used'].items(), key=lambda x: x[1])
                st.metric(
                    "ğŸ† ì£¼ ì‚¬ìš© ëª¨ë¸",
                    most_used[0].split(' - ')[0],
                    f"{most_used[1]}íšŒ"
                )
            else:
                st.metric("ğŸ† ì£¼ ì‚¬ìš© ëª¨ë¸", "-", None)
            st.markdown('</div>', unsafe_allow_html=True)
    
    def process_document(self, input_data: Dict[str, Any], is_refinement: bool = False, use_loop_agent: bool = True) -> Dict[str, Any]:
        """Process document through the pipeline with optional LoopAgent"""
        try:
            # Initialize multi-model agent if not already done
            if not self.multi_model_agent:
                agent_config = config.get_agent_config()
                self.multi_model_agent = MultiModelAgent(agent_config)
            
            # Show progress with animation
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # Get selected provider and model
            provider = st.session_state.selected_provider
            model = st.session_state.selected_model
            
            if model:
                # Update config with selected model
                if provider == "Anthropic":
                    self.multi_model_agent.config['anthropic_model'] = model
                elif provider == "OpenAI":
                    self.multi_model_agent.config['openai_model'] = model
                elif provider == "Google":
                    self.multi_model_agent.config['google_model'] = model
            
            # Animated progress
            with progress_placeholder.container():
                progress_bar = st.progress(0)
                for i in range(0, 101, 5):
                    progress_bar.progress(i)
                    if i < 30:
                        status_placeholder.info(f"ğŸ”§ ëª¨ë¸ ì¤€ë¹„ ì¤‘... ({provider})")
                    elif i < 70:
                        status_placeholder.info(f"âœï¸ ë¬¸ì„œ ìƒì„± ì¤‘... ({provider})")
                    else:
                        status_placeholder.info("ğŸ” í’ˆì§ˆ ê²€ì¦ ì¤‘...")
                    time.sleep(0.1)
            
            # Check if we should use LoopAgent for iterative improvement
            if use_loop_agent and not is_refinement:
                # Use LoopAgent for comprehensive critique and refinement
                status_placeholder.info("ğŸ”„ ADK LoopAgentë¡œ ë¬¸ì„œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì¤‘...")
                
                # Prepare config for LoopAgent
                loop_config = config.get_agent_config()
                loop_config['provider'] = provider
                loop_config['model'] = model
                
                # Also set provider-specific model keys
                if provider == "Anthropic":
                    loop_config['anthropic_model'] = model
                elif provider == "OpenAI":
                    loop_config['openai_model'] = model
                elif provider == "Google":
                    loop_config['google_model'] = model
                
                # Create and run LoopAgent
                from src.agents.loop_agent import LoopAgent
                loop_agent = LoopAgent(loop_config)
                
                # Run the loop agent with comprehensive improvement
                loop_result = loop_agent.run({
                    "document_type": input_data.get('document_type'),
                    "context": input_data.get('requirements'),
                    "tone": input_data.get('tone'),
                    "recipient": input_data.get('recipient', ''),
                    "subject": input_data.get('subject', ''),
                    "additional_context": input_data.get('additional_context', ''),
                    "provider": provider,
                    "model": model
                })
                
                # Extract results
                final_doc = loop_result.get('final_document', '')
                quality_score = loop_result.get('quality_score', 0.0)
                iterations = loop_result.get('iterations', 1)
                
                # Save draft from first iteration
                if loop_result.get('history') and len(loop_result['history']) > 0:
                    first_iteration = loop_result['history'][0].get('result', {})
                    draft_doc = first_iteration.get('draft', final_doc)
                    st.session_state.draft_document = draft_doc
                    st.session_state.refinement_history = [{
                        'version': 'ì´ˆì•ˆ',
                        'content': draft_doc,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {model}"
                    }]
                    
                    # Save critique history for diff analysis
                    st.session_state.critique_history = []
                    
                    # Add refinement history from loop iterations
                    for i, hist in enumerate(loop_result['history'], 1):
                        result = hist.get('result', {})
                        refined_content = result.get('refined_content', '')
                        critique = result.get('critique', '')
                        
                        if refined_content:
                            st.session_state.refinement_history.append({
                                'version': f'ê°œì„  {i}',
                                'content': refined_content,
                                'timestamp': hist.get('timestamp', datetime.now().isoformat()),
                                'model': f"{provider} - {model}",
                                'quality_score': result.get('quality_score', 0)
                            })
                        
                        if critique:
                            st.session_state.critique_history.append({
                                'iteration': i,
                                'critique': critique,
                                'quality_score': result.get('quality_score', 0),
                                'issues': result.get('issues_found', []),
                                'suggestions': result.get('suggestions', [])
                            })
                
                # Update status
                status_placeholder.success(
                    f"âœ… LoopAgent ì™„ë£Œ! "
                    f"ì´ {iterations}íšŒ ë°˜ë³µ, "
                    f"í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}, "
                    f"ì¢…ë£Œ ì‚¬ìœ : {loop_result.get('exit_reason', 'Unknown')}"
                )
                
            else:
                # Simple generation without LoopAgent
                prompt = self._create_prompt(input_data)
                
                # Generate response
                response = self.multi_model_agent.generate(
                    prompt,
                    provider=provider,
                    temperature=input_data.get('temperature', 0.7),
                    max_tokens=input_data.get('max_tokens', 2048)
                )
                
                final_doc = response.content
                
                # Save draft if first generation
                if not is_refinement and not st.session_state.draft_document:
                    st.session_state.draft_document = response.content
                    st.session_state.refinement_history = [{
                        'version': 'ì´ˆì•ˆ',
                        'content': response.content,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {response.model_used}"
                    }]
                
                # Calculate quality score for simple generation
                term_validation = validate_financial_terms(final_doc)
                compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
                quality_score = calculate_quality_score(final_doc, term_validation, compliance_check)
                iterations = 1
            
            # Clear progress
            progress_placeholder.empty()
            status_placeholder.empty()
            
            # Final validation (for all paths)
            term_validation = validate_financial_terms(final_doc)
            compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
            final_score = quality_score if use_loop_agent and not is_refinement else calculate_quality_score(final_doc, term_validation, compliance_check)
            
            # Update model usage stats
            model_used = model if use_loop_agent and not is_refinement else response.model_used if 'response' in locals() else model
            model_key = f"{provider} - {model_used}"
            if model_key not in st.session_state.stats['models_used']:
                st.session_state.stats['models_used'][model_key] = 0
            st.session_state.stats['models_used'][model_key] += 1
            
            result = {
                "success": True,
                "final_document": final_doc,
                "quality_score": final_score,
                "iterations": iterations if 'iterations' in locals() else 1,
                "total_time": 5.0,
                "provider": provider,
                "model_used": model_used,
                "validation": {
                    "terms": term_validation,
                    "compliance": compliance_check,
                    "final_score": final_score
                }
            }
            
            # Update stats
            self._update_stats(result)
            
            return result
            
        except Exception as e:
            progress_placeholder.empty()
            status_placeholder.empty()
            return {"error": str(e), "success": False}
    
    def _create_prompt(self, input_data: Dict[str, Any]) -> str:
        """Create prompt for document generation"""
        doc_type = config.DOCUMENT_TYPES.get(input_data['document_type'], input_data['document_type'])
        
        prompt = f"""ë‹¹ì‹ ì€ ì½”ìŠ¤ì½¤ ê¸ˆìœµì˜ì—…ë¶€ì˜ ì „ë¬¸ ë¬¸ì„œ ì‘ì„± AIì…ë‹ˆë‹¤.
        
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ê³¼ ì¶”ê°€ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ {doc_type}ì„(ë¥¼) ì‘ì„±í•´ì£¼ì„¸ìš”:

[í•µì‹¬ ìš”êµ¬ì‚¬í•­]
{input_data['requirements']}

[ë¬¸ì„œ ìŠ¤íƒ€ì¼]
í†¤ì•¤ë§¤ë„ˆ: {input_data['tone']}
"""
        
        if input_data.get('recipient'):
            prompt += f"\n\n[ìˆ˜ì‹ ì ì •ë³´]\nìˆ˜ì‹ ì: {input_data['recipient']}"
            prompt += "\n- ìˆ˜ì‹ ìì—ê²Œ ì í•©í•œ í˜¸ì¹­ê³¼ ì¡´ì¹­ì„ ì‚¬ìš©í•˜ì„¸ìš”"
            prompt += "\n- ìˆ˜ì‹ ìì˜ ì…ì¥ê³¼ ê´€ì‹¬ì‚¬ë¥¼ ê³ ë ¤í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”"
        
        if input_data.get('subject'):
            prompt += f"\n\n[ì œëª©/ì£¼ì œ]\n{input_data['subject']}"
            prompt += "\n- ì œëª©ê³¼ ì¼ê´€ì„± ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”"
            prompt += "\n- í•µì‹¬ ë©”ì‹œì§€ê°€ ëª…í™•íˆ ì „ë‹¬ë˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”"
        
        if input_data.get('additional_context'):
            prompt += f"\n\n[ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ë° íŠ¹ë³„ ì§€ì‹œì‚¬í•­]\n{input_data['additional_context']}"
            prompt += "\n- ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”"
            prompt += "\n- íŠ¹ë³„íˆ ê°•ì¡°ëœ ì‚¬í•­ì€ ë¬¸ì„œì—ì„œ ë¶€ê°ì‹œì¼œ ì£¼ì„¸ìš”"
        
        # Add length preference
        length_pref = input_data.get('length_preference', 'medium')
        
        prompt += """

[ì‘ì„± ê¸°ì¤€]
1. ìš”êµ¬ì‚¬í•­ì˜ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ë°˜ì˜
2. ì¶”ê°€ ì •ë³´ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì ì ˆíˆ í™œìš©
3. ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©
4. ê·œì • ì¤€ìˆ˜ ë° ë²•ì  ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
5. ëª…í™•í•˜ê³  ë…¼ë¦¬ì ì¸ ë¬¸ì¥ êµ¬ì„±
6. ì ì ˆí•œ êµ¬ì¡°ì™€ í˜•ì‹ ì¤€ìˆ˜
7. ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„
8. ì½”ìŠ¤ì½¤ ê¸ˆìœµì˜ì—…ë¶€ì˜ ì „ë¬¸ì„±ê³¼ ì‹ ë¢°ì„± ë°˜ì˜
"""
        
        # Add length-specific instructions
        if length_pref == "short":
            prompt += "\n[ë¬¸ì„œ ê¸¸ì´] âš¡ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©ìœ¼ë¡œ 1-2ë‹¨ë½ ì´ë‚´ë¡œ ì‘ì„±"
        elif length_pref == "long":
            prompt += "\n[ë¬¸ì„œ ê¸¸ì´] ğŸ“š ìƒì„¸í•˜ê³  ì¢…í•©ì ì¸ ë‚´ìš©ìœ¼ë¡œ 5-7ë‹¨ë½ ì´ìƒ ì‘ì„±"
        else:
            prompt += "\n[ë¬¸ì„œ ê¸¸ì´] ğŸ“„ ì ì ˆí•œ ê¸¸ì´ë¡œ 3-4ë‹¨ë½ ì •ë„ë¡œ ì‘ì„±"
        
        prompt += """

ë°œì‹ : ì½”ìŠ¤ì½¤ ê¸ˆìœµì˜ì—…ë¶€

ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
"""
        
        return prompt
    
    def _update_stats(self, result: Dict[str, Any]):
        """Update statistics"""
        # Update session state stats
        stats = st.session_state.stats
        stats['total_documents'] += 1
        
        current_quality = result.get('quality_score', 0)
        stats['avg_quality'] = (
            (stats['avg_quality'] * (stats['total_documents'] - 1) + current_quality) 
            / stats['total_documents']
        )
        
        current_iter = result.get('iterations', 0)
        stats['avg_iterations'] = (
            (stats['avg_iterations'] * (stats['total_documents'] - 1) + current_iter)
            / stats['total_documents']
        )
        
        stats['total_time'] += result.get('total_time', 0)
        
        # Stats are also automatically updated in database when saving document
    
    def run(self):
        """Run the application"""
        # Header
        self.render_header()
        
        # Sidebar with model selection and settings
        with st.sidebar:
            st.markdown("---")
            
            # Model selector in sidebar
            providers_available = self.render_sidebar_model_selector()
            
            if not providers_available:
                st.stop()
            
            st.markdown("---")
            
            # Model settings
            st.markdown("## âš™ï¸ ëª¨ë¸ ì„¤ì •")
            
            temperature = st.slider(
                "ğŸŒ¡ï¸ Temperature (ì°½ì˜ì„±)",
                min_value=0.0,
                max_value=1.0,
                value=config.TEMPERATURE,
                step=0.1,
                help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆê³ , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì…ë‹ˆë‹¤"
            )
            
            max_tokens = st.number_input(
                "ğŸ“ ìµœëŒ€ í† í° ìˆ˜",
                min_value=500,
                max_value=4000,
                value=config.MAX_OUTPUT_TOKENS,
                step=100,
                help="ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´"
            )
            
            st.markdown("---")
            
            # Document settings
            st.markdown("## ğŸ“„ ë¬¸ì„œ ì„¤ì •")
            
            doc_type = st.selectbox(
                "ë¬¸ì„œ ìœ í˜•",
                options=list(config.DOCUMENT_TYPES.keys()),
                format_func=lambda x: config.DOCUMENT_TYPES[x],
                help="ì‘ì„±í•  ë¬¸ì„œì˜ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            tone = st.select_slider(
                "í†¤ì•¤ë§¤ë„ˆ",
                options=["formal", "professional", "professional_premium", "analytical", "urgent", "friendly"],
                value=st.session_state.get('example_tone', 'professional'),
                format_func=lambda x: {
                    "formal": "ê²©ì‹ìˆëŠ”",
                    "professional": "ì „ë¬¸ì ì¸",
                    "professional_premium": "í”„ë¦¬ë¯¸ì—„ (VIPìš©)",
                    "analytical": "ë¶„ì„ì ì¸",
                    "urgent": "ê¸´ê¸‰í•œ",
                    "friendly": "ì¹œê·¼í•œ"
                }.get(x, x),
                help="ë¬¸ì„œì˜ í†¤ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # Document length preference
            doc_length = st.select_slider(
                "ğŸ“ ë¬¸ì„œ ê¸¸ì´",
                options=["short", "medium", "long"],
                value="medium",
                format_func=lambda x: {
                    "short": "ê°„ê²° (1-2ë‹¨ë½)",
                    "medium": "ë³´í†µ (3-4ë‹¨ë½)",
                    "long": "ìƒì„¸ (5-7ë‹¨ë½+)"
                }.get(x, x),
                help="ìƒì„±í•  ë¬¸ì„œì˜ ê¸¸ì´ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # Advanced prompt settings
            with st.expander("ğŸ§ª ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
                use_context7 = st.checkbox(
                    "ğŸ“š Context7 íŒ¨í„´ ì‚¬ìš©",
                    value=True,
                    help="Context7 ë¬¸ì„œ êµ¬ì¡° íŒ¨í„´ê³¼ ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ë¥¼ ì ìš©í•©ë‹ˆë‹¤"
                )
                
                use_sequential = st.checkbox(
                    "ğŸ”„ Sequential Thinking ì‚¬ìš©",
                    value=True,
                    help="ì²´ê³„ì ì¸ ìˆœì°¨ ì‚¬ê³  í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤"
                )
                
                if st.button("ğŸ¯ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì ìš©", use_container_width=True):
                    # Get current requirements from session state if available
                    current_requirements = st.session_state.get('requirements_input', '')
                    if current_requirements:
                        # Build a temporary example from current inputs
                        temp_example = {
                            'title': doc_type,
                            'requirements': current_requirements,
                            'recipient': st.session_state.get('recipient_input', ''),
                            'subject': st.session_state.get('subject_input', ''),
                            'additional_context': st.session_state.get('context_input', ''),
                            'tone': tone,
                            'length': doc_length
                        }
                        
                        enhanced_prompt = self.example_templates.generate_advanced_prompt(
                            temp_example,
                            use_context7=use_context7,
                            use_sequential=use_sequential,
                            length_preference=doc_length
                        )
                        
                        st.session_state.example_requirements = enhanced_prompt
                        st.success("âœ¨ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.warning("ë¨¼ì € ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            st.markdown("---")
            
            # Quick actions
            st.markdown("## ğŸš€ ë¹ ë¥¸ ì‹¤í–‰")
            
            if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.history = []
                st.session_state.current_result = None
                st.rerun()
            
            if st.button("ğŸ“Š í†µê³„ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.stats = {
                    'total_documents': 0,
                    'avg_quality': 0,
                    'avg_iterations': 0,
                    'total_time': 0,
                    'models_used': {}
                }
                st.rerun()
        
        # Main content area
        st.markdown("---")
        
        # Stats dashboard
        self.render_stats()
        
        st.markdown("---")
        
        # Tabs for different features
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "âœï¸ ë¬¸ì„œ ì‘ì„±",
            "ğŸ”„ ì´ˆì•ˆ vs ìµœì¢…",
            "ğŸ”€ ë³€ê²½ ì‚¬í•­ ë¶„ì„",
            "ğŸ” ëª¨ë¸ ë¹„êµ",
            "ğŸ“Š ë¶„ì„",
            "ğŸ“š ì´ë ¥"
        ])
        
        with tab1:
            col1, col2 = st.columns([1, 1], gap="large")
            
            with col1:
                st.markdown("### ğŸ“ ë¬¸ì„œ ìš”êµ¬ì‚¬í•­")
                
                # Use example values if available
                req_value = st.session_state.get('example_requirements', '')
                requirements = st.text_area(
                    "ìš”êµ¬ì‚¬í•­",
                    value=req_value,
                    placeholder="ì‘ì„±í•˜ê³ ì í•˜ëŠ” ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”...\n\nì˜ˆì‹œ:\n- ì‹ ê·œ ê¸ˆìœµ ìƒí’ˆ ì•ˆë‚´ ì´ë©”ì¼\n- íˆ¬ì ì œì•ˆì„œ ì´ˆì•ˆ\n- ê·œì • ì¤€ìˆ˜ ë³´ê³ ì„œ",
                    height=250,
                    label_visibility="collapsed",
                    key="requirements_input"
                )
                
                # Check if we have example data
                has_example = any([
                    'example_recipient' in st.session_state,
                    'example_subject' in st.session_state,
                    'example_context' in st.session_state
                ])
                
                with st.expander("ğŸ“ ì¶”ê°€ ì •ë³´", expanded=has_example):
                    recipient = st.text_input(
                        "ìˆ˜ì‹ ì",
                        value=st.session_state.get('example_recipient', ''),
                        placeholder="ì˜ˆ: ê¹€ì² ìˆ˜ ëŒ€í‘œë‹˜",
                        key="recipient_input"
                    )
                    subject = st.text_input(
                        "ì œëª©",
                        value=st.session_state.get('example_subject', ''),
                        placeholder="ì˜ˆ: 2024ë…„ ì‹ ê·œ íˆ¬ì ìƒí’ˆ ì•ˆë‚´",
                        key="subject_input"
                    )
                    additional_context = st.text_area(
                        "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸",
                        value=st.session_state.get('example_context', ''),
                        placeholder="íŠ¹ë³„íˆ ê°•ì¡°í•˜ê±°ë‚˜ í¬í•¨í•´ì•¼ í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...",
                        height=100,
                        key="context_input"
                    )
                
                # Clean up example data after use
                if req_value and requirements != req_value:
                    for key in ['example_requirements', 'example_recipient', 'example_subject', 'example_context', 'example_tone']:
                        if key in st.session_state:
                            del st.session_state[key]
                
                # LoopAgent ì‚¬ìš© ì˜µì…˜
                use_loop = st.checkbox(
                    "ğŸ”„ ADK LoopAgentë¡œ ë¹„í‰ ë° ê°œì„  ìˆ˜í–‰",
                    value=True,
                    help="ì²´í¬í•˜ë©´ ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ë²ˆ ë¹„í‰í•˜ê³  ê°œì„ í•˜ì—¬ í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤."
                )
                
                col1_1, col1_2 = st.columns(2)
                with col1_1:
                    if st.button("ğŸš€ ë¬¸ì„œ ìƒì„±", type="primary", use_container_width=True):
                        if requirements:
                            if not st.session_state.selected_model:
                                st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ AI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            else:
                                input_data = {
                                    "document_type": doc_type,
                                    "requirements": requirements,
                                    "tone": tone,
                                    "recipient": recipient,
                                    "subject": subject,
                                    "additional_context": additional_context,
                                    "temperature": temperature,
                                    "max_tokens": max_tokens,
                                    "length_preference": doc_length
                                }
                                
                                result = self.process_document(input_data, use_loop_agent=use_loop)
                                
                                st.session_state.current_result = result
                                # Save to database
                                doc_data = {
                                    "timestamp": datetime.now().isoformat(),
                                    "input": input_data,
                                    "result": result
                                }
                                
                                try:
                                    doc_id = self.db.save_document(doc_data)
                                    result['document_id'] = doc_id
                                except Exception as e:
                                    logger.error(f"Error saving to database: {str(e)}")
                                
                                st.session_state.history.append(doc_data)
                                
                                if result.get("success"):
                                    st.success(f"âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ! (ëª¨ë¸: {result.get('model_used', 'Unknown')})")
                                    st.balloons()
                                else:
                                    st.error(f"âŒ ì˜¤ë¥˜: {result.get('error')}")
                        else:
                            st.warning("ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                with col1_2:
                    if st.button("ğŸ² ì˜ˆì‹œ ì„ íƒ", use_container_width=True, key="example_selector_btn"):
                        st.session_state.show_example_selector = not st.session_state.get('show_example_selector', False)
                
                # Example selector dialog
                if st.session_state.get('show_example_selector', False):
                    with st.container():
                        st.markdown("### ğŸ“š ì½”ìŠ¤ì½¤ ê¸ˆìœµì˜ì—…ë¶€ ìµœì í™” ì˜ˆì‹œ")
                        
                        # Document type filter
                        example_category = st.selectbox(
                            "ë¬¸ì„œ ìœ í˜• ì„ íƒ",
                            ["ì „ì²´"] + [
                                "email (ì´ë©”ì¼)",
                                "proposal (ì œì•ˆì„œ)",
                                "report (ë³´ê³ ì„œ)",
                                "official (ê³µì‹ë¬¸ì„œ)"
                            ],
                            key="example_category_select"
                        )
                        
                        # Get examples based on category
                        if example_category == "ì „ì²´":
                            examples = []
                            for cat in ['email', 'proposal', 'report', 'official']:
                                examples.extend(self.example_templates.get_examples_by_category(cat))
                        else:
                            cat_key = example_category.split(' ')[0]
                            examples = self.example_templates.get_examples_by_category(cat_key)
                        
                        # Display examples in a grid
                        if examples:
                            for idx, example in enumerate(examples):
                                with st.expander(f"{example['title']} - {example['category']}", expanded=False):
                                    st.write(example.get('requirements', '')[:200] + "...")
                                    
                                    # Advanced options
                                    col_opt1, col_opt2, col_opt3 = st.columns(3)
                                    with col_opt1:
                                        use_c7 = st.checkbox(
                                            "Context7 íŒ¨í„´",
                                            value=True,
                                            key=f"c7_{idx}",
                                            help="Context7 ë¬¸ì„œ êµ¬ì¡° íŒ¨í„´ ì ìš©"
                                        )
                                    with col_opt2:
                                        use_seq = st.checkbox(
                                            "Sequential",
                                            value=True,
                                            key=f"seq_{idx}",
                                            help="Sequential Thinking ì ìš©"
                                        )
                                    with col_opt3:
                                        length_pref = st.select_slider(
                                            "ê¸¸ì´",
                                            options=["short", "medium", "long"],
                                            value=example.get('length', 'medium'),
                                            key=f"length_{idx}"
                                        )
                                    
                                    if st.button(
                                        "âœ… ì´ ì˜ˆì‹œ ì‚¬ìš©",
                                        key=f"use_example_{idx}",
                                        use_container_width=True,
                                        type="primary"
                                    ):
                                        # Generate advanced prompt
                                        advanced_prompt = self.example_templates.generate_advanced_prompt(
                                            example,
                                            use_context7=use_c7,
                                            use_sequential=use_seq,
                                            length_preference=length_pref
                                        )
                                        
                                        # Set the values
                                        st.session_state.example_requirements = advanced_prompt
                                        st.session_state.example_recipient = example.get('recipient', '')
                                        st.session_state.example_subject = example.get('subject', '')
                                        st.session_state.example_context = example.get('additional_context', '')
                                        st.session_state.example_tone = example.get('tone', 'professional')
                                        st.session_state.show_example_selector = False
                                        st.rerun()
                        
                        # Close button
                        if st.button("âŒ ë‹«ê¸°", use_container_width=True):
                            st.session_state.show_example_selector = False
                            st.rerun()
            
            with col2:
                st.markdown("### ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ")
                
                if st.session_state.current_result and st.session_state.current_result.get("success"):
                    result = st.session_state.current_result
                    
                    # Model info badge
                    provider = result.get('provider', 'Unknown')
                    model = result.get('model_used', 'Unknown')
                    
                    col2_1, col2_2 = st.columns([2, 1])
                    with col2_1:
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            <strong>ğŸ¤– {provider}</strong> | {model}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2_2:
                        quality_score = result.get('quality_score', 0)
                        if quality_score >= 0.9:
                            quality_badge = "ğŸ† ìš°ìˆ˜"
                            quality_color = "#00b894"
                        elif quality_score >= 0.8:
                            quality_badge = "âœ… ì–‘í˜¸"
                            quality_color = "#fdcb6e"
                        else:
                            quality_badge = "âš ï¸ ê°œì„ í•„ìš”"
                            quality_color = "#d63031"
                        
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: {quality_color}; 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            {quality_badge} {quality_score:.1%}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Document content
                    st.text_area(
                        "ìµœì¢… ë¬¸ì„œ",
                        value=result.get("final_document", ""),
                        height=350,
                        label_visibility="collapsed"
                    )
                    
                    # Metrics
                    col2_1, col2_2, col2_3 = st.columns(3)
                    with col2_1:
                        st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_time', 0):.1f}ì´ˆ")
                    with col2_2:
                        doc_length = len(result.get("final_document", ""))
                        st.metric("ğŸ“ ë¬¸ì„œ ê¸¸ì´", f"{doc_length:,}ì")
                    with col2_3:
                        word_count = len(result.get("final_document", "").split())
                        st.metric("ğŸ“ ë‹¨ì–´ ìˆ˜", f"{word_count:,}ê°œ")
                    
                    # Download button
                    st.download_button(
                        label="ğŸ“¥ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=result["final_document"],
                        file_name=f"document_{provider}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                else:
                    st.info("ğŸ’¡ ì™¼ìª½ì—ì„œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ê³  'ë¬¸ì„œ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                    
                    # Show example if available
                    if hasattr(st.session_state, 'example_text'):
                        st.markdown("#### ì˜ˆì‹œ ìš”êµ¬ì‚¬í•­:")
                        st.info(st.session_state.example_text)
        
        with tab2:
            st.markdown("### ğŸ”„ ì´ˆì•ˆ vs ìµœì¢… ë¬¸ì„œ ë¹„êµ")
            
            if st.session_state.draft_document and st.session_state.current_result:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ“ ì´ˆì•ˆ")
                    st.text_area(
                        "ì´ˆì•ˆ ë¬¸ì„œ",
                        value=st.session_state.draft_document,
                        height=400,
                        label_visibility="collapsed",
                        key="draft_compare"
                    )
                    
                    # Draft metrics
                    draft_terms = validate_financial_terms(st.session_state.draft_document)
                    draft_compliance = check_compliance(st.session_state.draft_document, "email")
                    draft_score = calculate_quality_score(st.session_state.draft_document, draft_terms, draft_compliance)
                    
                    st.metric("ì´ˆì•ˆ í’ˆì§ˆ", f"{draft_score:.1%}")
                    st.metric("ì´ˆì•ˆ ê¸¸ì´", f"{len(st.session_state.draft_document):,}ì")
                
                with col2:
                    st.markdown("#### âœ¨ ìµœì¢… ë¬¸ì„œ")
                    final_doc = st.session_state.current_result.get('final_document', '')
                    st.text_area(
                        "ìµœì¢… ë¬¸ì„œ",
                        value=final_doc,
                        height=400,
                        label_visibility="collapsed",
                        key="final_compare"
                    )
                    
                    # Final metrics
                    final_score = st.session_state.current_result.get('quality_score', 0)
                    st.metric("ìµœì¢… í’ˆì§ˆ", f"{final_score:.1%}")
                    st.metric("ìµœì¢… ê¸¸ì´", f"{len(final_doc):,}ì")
                
                # Improvement analysis
                st.markdown("#### ğŸ“ˆ ê°œì„  ë¶„ì„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    improvement = (final_score - draft_score) * 100
                    if improvement > 0:
                        st.success(f"í’ˆì§ˆ ê°œì„ : +{improvement:.1f}%")
                    elif improvement < 0:
                        st.error(f"í’ˆì§ˆ í•˜ë½: {improvement:.1f}%")
                    else:
                        st.info("í’ˆì§ˆ ë™ì¼")
                
                with col2:
                    length_change = len(final_doc) - len(st.session_state.draft_document)
                    if length_change > 0:
                        st.info(f"ê¸¸ì´ ì¦ê°€: +{length_change:,}ì")
                    elif length_change < 0:
                        st.info(f"ê¸¸ì´ ê°ì†Œ: {length_change:,}ì")
                    else:
                        st.info("ê¸¸ì´ ë™ì¼")
                
                with col3:
                    if st.button("â™»ï¸ ë¬¸ì„œ ì¬ì •ì œ", use_container_width=True):
                        # Refine document again
                        refinement_prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ë” ê°œì„ í•´ì£¼ì„¸ìš”:\n\n{final_doc}"
                        input_data = st.session_state.current_result.get('input', {})
                        input_data['requirements'] = refinement_prompt
                        
                        with st.spinner("ë¬¸ì„œë¥¼ ì¬ì •ì œí•˜ëŠ” ì¤‘..."):
                            refined_result = self.process_document(input_data, is_refinement=True)
                            if refined_result.get('success'):
                                st.session_state.current_result = refined_result
                                st.session_state.refinement_history.append({
                                    'version': f"ì •ì œ {len(st.session_state.refinement_history)}",
                                    'content': refined_result.get('final_document', ''),
                                    'timestamp': datetime.now().isoformat(),
                                    'model': f"{refined_result.get('provider')} - {refined_result.get('model_used')}"
                                })
                                st.success("ë¬¸ì„œê°€ ì¬ì •ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.rerun()
                
                # Refinement history
                if len(st.session_state.refinement_history) > 1:
                    st.markdown("#### ğŸ“š ì •ì œ ì´ë ¥")
                    for idx, version in enumerate(st.session_state.refinement_history):
                        with st.expander(f"{version['version']} - {version['model']}"):
                            st.text_area(
                                f"ë²„ì „ {idx}",
                                value=version['content'][:500] + "...",
                                height=150,
                                label_visibility="collapsed",
                                key=f"version_{idx}"
                            )
            else:
                st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë¬¸ì„œ ì‘ì„± íƒ­ì—ì„œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ê³  ìƒì„± ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        
        with tab3:
            st.markdown("### ğŸ”€ ë³€ê²½ ì‚¬í•­ ìƒì„¸ ë¶„ì„")
            
            if st.session_state.draft_document and st.session_state.current_result:
                # View mode selector
                view_mode = st.radio(
                    "ë¶„ì„ ëª¨ë“œ",
                    ["ë³€ê²½ ì‚¬í•­ ìš”ì•½", "ë¼ì¸ë³„ ë¹„êµ", "ë‹¨ì–´ë³„ ë¹„êµ", "ìˆ˜ì • ì´ìœ  ë¶„ì„"],
                    horizontal=True
                )
                
                draft_doc = st.session_state.draft_document
                final_doc = st.session_state.current_result.get('final_document', '')
                
                if view_mode == "ë³€ê²½ ì‚¬í•­ ìš”ì•½":
                    # Statistics
                    stats = get_change_statistics(draft_doc, final_doc)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric(
                            "ë¬¸ì„œ ìœ ì‚¬ë„",
                            f"{stats['similarity']:.1f}%",
                            help="ì´ˆì•ˆê³¼ ìµœì¢…ë³¸ì˜ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„"
                        )
                    with col2:
                        st.metric(
                            "ê¸¸ì´ ë³€í™”",
                            f"{stats['length_change']:+,}ì",
                            f"{stats['length_change_percent']:+.1f}%"
                        )
                    with col3:
                        st.metric(
                            "ë‹¨ì–´ ìˆ˜ ë³€í™”",
                            f"{stats['word_change']:+,}ê°œ",
                            help="ì´ ë‹¨ì–´ ìˆ˜ì˜ ë³€í™”"
                        )
                    with col4:
                        st.metric(
                            "ë¬¸ì¥ ìˆ˜ ë³€í™”",
                            f"{stats['sentences_final'] - stats['sentences_original']:+,}ê°œ",
                            help="ë¬¸ì¥ ê°œìˆ˜ì˜ ë³€í™”"
                        )
                    
                    # Modification summary from critique history
                    if st.session_state.critique_history:
                        st.markdown("#### ğŸ“ ì£¼ìš” ìˆ˜ì • ì‚¬í•­")
                        
                        all_modifications = []
                        for critique_item in st.session_state.critique_history:
                            critique_text = critique_item.get('critique', '')
                            if critique_text:
                                mods = extract_modifications(critique_text)
                                all_modifications.extend(mods)
                        
                        if all_modifications:
                            summary_html = create_modification_summary(all_modifications)
                            st.markdown(summary_html, unsafe_allow_html=True)
                        else:
                            st.info("ìˆ˜ì • ì‚¬í•­ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # Quality improvement timeline
                    if st.session_state.critique_history:
                        st.markdown("#### ğŸ“ˆ í’ˆì§ˆ ê°œì„  ì¶”ì´")
                        
                        iterations = []
                        scores = []
                        for critique_item in st.session_state.critique_history:
                            iterations.append(f"ë°˜ë³µ {critique_item['iteration']}")
                            scores.append(critique_item.get('quality_score', 0) * 100)
                        
                        # Simple chart using columns
                        chart_cols = st.columns(len(iterations))
                        for i, (iter_name, score) in enumerate(zip(iterations, scores)):
                            with chart_cols[i]:
                                st.metric(iter_name, f"{score:.0f}%")
                
                elif view_mode == "ë¼ì¸ë³„ ë¹„êµ":
                    st.markdown("#### ğŸ“„ ë¼ì¸ë³„ ì°¨ì´ì ")
                    
                    # Create line diff
                    diff_html = create_diff_html(draft_doc, final_doc, "ì´ˆì•ˆ", "ìµœì¢…")
                    st.markdown(diff_html, unsafe_allow_html=True)
                    
                    # Download diff as text
                    diff_text = f"=== ì´ˆì•ˆ ===\n{draft_doc}\n\n=== ìµœì¢… ===\n{final_doc}"
                    st.download_button(
                        "ğŸ“¥ ë¹„êµ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        diff_text,
                        file_name=f"diff_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                elif view_mode == "ë‹¨ì–´ë³„ ë¹„êµ":
                    st.markdown("#### ğŸ“ ë‹¨ì–´ ìˆ˜ì¤€ ë³€ê²½ì‚¬í•­")
                    
                    word_diff_html, word_stats = create_word_diff(draft_doc, final_doc)
                    
                    # Show statistics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì¶”ê°€ëœ ë‹¨ì–´", word_stats['added'])
                    with col2:
                        st.metric("ì‚­ì œëœ ë‹¨ì–´", word_stats['removed'])
                    with col3:
                        st.metric("ì´ ë³€ê²½", word_stats['total_changes'])
                    
                    # Show word diff
                    st.markdown(
                        f'<div style="background: white; padding: 1rem; border-radius: 8px; line-height: 1.8;">{word_diff_html}</div>',
                        unsafe_allow_html=True
                    )
                
                elif view_mode == "ìˆ˜ì • ì´ìœ  ë¶„ì„":
                    st.markdown("#### ğŸ” ìˆ˜ì • ì´ìœ  ë° ê·¼ê±°")
                    
                    if st.session_state.critique_history:
                        for i, critique_item in enumerate(st.session_state.critique_history, 1):
                            with st.expander(f"ë°˜ë³µ {i} - í’ˆì§ˆ ì ìˆ˜: {critique_item.get('quality_score', 0):.1%}"):
                                critique_text = critique_item.get('critique', '')
                                
                                # Display issues
                                issues = critique_item.get('issues', [])
                                if issues:
                                    st.markdown("**ë°œê²¬ëœ ë¬¸ì œì :**")
                                    for issue in issues:
                                        st.markdown(f"- âš ï¸ {issue}")
                                
                                # Display suggestions
                                suggestions = critique_item.get('suggestions', [])
                                if suggestions:
                                    st.markdown("**ê°œì„  ì œì•ˆ:**")
                                    for suggestion in suggestions:
                                        st.markdown(f"- ğŸ’¡ {suggestion}")
                                
                                # Display full critique
                                if critique_text:
                                    st.markdown("**ìƒì„¸ ë¹„í‰:**")
                                    st.text_area(
                                        "ë¹„í‰ ë‚´ìš©",
                                        value=critique_text,
                                        height=200,
                                        label_visibility="collapsed",
                                        key=f"critique_{i}"
                                    )
                    else:
                        st.info("LoopAgentë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´ ìƒì„¸í•œ ìˆ˜ì • ì´ìœ ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                # Export options
                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ“Š ë¶„ì„ ë³´ê³ ì„œ ìƒì„±", use_container_width=True):
                        # Generate comprehensive report
                        report = f"""# ë¬¸ì„œ ê°œì„  ë¶„ì„ ë³´ê³ ì„œ
ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## 1. ê°œìš”
- ì´ˆì•ˆ ê¸¸ì´: {len(draft_doc):,}ì
- ìµœì¢… ê¸¸ì´: {len(final_doc):,}ì
- ë³€ê²½ë¥ : {((len(final_doc) - len(draft_doc)) / len(draft_doc) * 100):.1f}%
- ë¬¸ì„œ ìœ ì‚¬ë„: {calculate_similarity(draft_doc, final_doc) * 100:.1f}%

## 2. ì´ˆì•ˆ
{draft_doc}

## 3. ìµœì¢…ë³¸
{final_doc}

## 4. ì£¼ìš” ë³€ê²½ ì‚¬í•­
{' '.join([f"- {mod['description']}" for critique in st.session_state.critique_history for mod in extract_modifications(critique.get('critique', ''))][:5])}
"""
                        st.download_button(
                            "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                            report,
                            file_name=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
                
                with col2:
                    if st.button("ğŸ”„ ì¬ë¶„ì„", use_container_width=True):
                        st.rerun()
            
            else:
                st.info("ë¬¸ì„œë¥¼ ìƒì„±í•œ í›„ ë³€ê²½ ì‚¬í•­ ë¶„ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        with tab4:
            st.markdown("### ğŸ” ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ")
            st.info("ë™ì¼í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”.")
            
            compare_requirements = st.text_area(
                "ë¹„êµí•  ë¬¸ì„œ ìš”êµ¬ì‚¬í•­",
                placeholder="ëª¨ë“  ëª¨ë¸ì—ì„œ í…ŒìŠ¤íŠ¸í•  ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”...",
                height=150,
                key="compare_requirements"
            )
            
            # Model selection for comparison
            st.markdown("#### ë¹„êµí•  ëª¨ë¸ ì„ íƒ")
            col1, col2, col3 = st.columns(3)
            
            compare_models = []
            with col1:
                if config.ANTHROPIC_API_KEY and st.checkbox("Anthropic Claude", value=True):
                    compare_models.append("Anthropic")
            with col2:
                if config.OPENAI_API_KEY and st.checkbox("OpenAI GPT", value=True):
                    compare_models.append("OpenAI")
            with col3:
                if config.GOOGLE_API_KEY and st.checkbox("Google Gemini", value=True):
                    compare_models.append("Google")
            
            if st.button("ğŸ”¬ ì„ íƒí•œ ëª¨ë¸ë¡œ ë¹„êµ ìƒì„±", type="primary", use_container_width=True):
                if compare_requirements and compare_models:
                    if not self.multi_model_agent:
                        agent_config = config.get_agent_config()
                        self.multi_model_agent = MultiModelAgent(agent_config)
                    
                    # Create input data
                    input_data = {
                        "document_type": doc_type,
                        "requirements": compare_requirements,
                        "tone": tone,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    }
                    
                    prompt = self._create_prompt(input_data)
                    
                    # Progress bar for comparison
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = {}
                    for idx, provider in enumerate(compare_models):
                        status_text.text(f"ğŸ¤– {provider} ëª¨ë¸ë¡œ ìƒì„± ì¤‘...")
                        progress_bar.progress((idx + 1) / len(compare_models))
                        
                        try:
                            response = self.multi_model_agent.generate(prompt, provider=provider)
                            results[provider] = response
                        except Exception as e:
                            st.error(f"{provider} ì˜¤ë¥˜: {str(e)}")
                    
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Display comparison results
                    if results:
                        st.markdown("#### ğŸ“Š ë¹„êµ ê²°ê³¼")
                        
                        # Create columns for side-by-side comparison
                        cols = st.columns(len(results))
                        
                        for idx, (provider, response) in enumerate(results.items()):
                            with cols[idx]:
                                st.markdown(f"##### {provider}")
                                
                                # Calculate quality score
                                term_validation = validate_financial_terms(response.content)
                                compliance_check = check_compliance(response.content, doc_type)
                                quality_score = calculate_quality_score(response.content, term_validation, compliance_check)
                                
                                # Quality badge
                                if quality_score >= 0.9:
                                    st.success(f"í’ˆì§ˆ: {quality_score:.1%}")
                                elif quality_score >= 0.8:
                                    st.warning(f"í’ˆì§ˆ: {quality_score:.1%}")
                                else:
                                    st.error(f"í’ˆì§ˆ: {quality_score:.1%}")
                                
                                st.text_area(
                                    f"{provider} ê²°ê³¼",
                                    value=response.content,
                                    height=400,
                                    label_visibility="collapsed",
                                    key=f"compare_{provider}"
                                )
                                
                                st.metric("ëª¨ë¸", response.model_used)
                                st.metric("ë¬¸ì ìˆ˜", f"{len(response.content):,}")
                else:
                    if not compare_requirements:
                        st.warning("ë¹„êµí•  ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    if not compare_models:
                        st.warning("ë¹„êµí•  ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        with tab4:
            st.markdown("### ğŸ“Š í†µê³„ ë° ë¶„ì„")
            
            # Statistics period selector
            col1, col2 = st.columns([3, 1])
            with col1:
                stat_period = st.selectbox(
                    "í†µê³„ ê¸°ê°„",
                    ["ì˜¤ëŠ˜", "ì§€ë‚œ 7ì¼", "ì§€ë‚œ 30ì¼", "ì „ì²´"],
                    index=2
                )
            with col2:
                if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                    self._load_statistics_from_db()
                    st.rerun()
            
            # Calculate period days
            if stat_period == "ì˜¤ëŠ˜":
                days = 1
            elif stat_period == "ì§€ë‚œ 7ì¼":
                days = 7
            elif stat_period == "ì§€ë‚œ 30ì¼":
                days = 30
            else:
                days = 365
            
            # Load statistics from database
            try:
                db_stats = self.db.get_statistics(days=days)
            except:
                db_stats = st.session_state.stats
            
            # Overall statistics
            st.markdown("#### ğŸ¯ ì „ì²´ í†µê³„")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ğŸ“„ ì´ ë¬¸ì„œ",
                    f"{db_stats.get('total_documents', 0):,}ê°œ",
                    delta=f"{len(st.session_state.history)}ê°œ (ì„¸ì…˜)"
                )
            
            with col2:
                avg_quality = db_stats.get('avg_quality', 0)
                st.metric(
                    "ğŸ† í‰ê·  í’ˆì§ˆ",
                    f"{avg_quality:.1%}",
                    delta="ìš°ìˆ˜" if avg_quality >= 0.9 else "ì–‘í˜¸"
                )
            
            with col3:
                st.metric(
                    "ğŸ”„ í‰ê·  ë°˜ë³µ",
                    f"{db_stats.get('avg_iterations', 0):.1f}íšŒ"
                )
            
            with col4:
                total_time = db_stats.get('total_time', 0)
                st.metric(
                    "â±ï¸ ì´ ì†Œìš”ì‹œê°„",
                    f"{total_time:.0f}ì´ˆ" if total_time < 3600 else f"{total_time/3600:.1f}ì‹œê°„"
                )
            
            # Provider statistics
            if db_stats.get('by_provider'):
                st.markdown("#### ğŸ¤– ëª¨ë¸ë³„ í†µê³„")
                provider_cols = st.columns(len(db_stats['by_provider']))
                for idx, (provider, count) in enumerate(db_stats['by_provider'].items()):
                    with provider_cols[idx]:
                        st.metric(provider, f"{count}ê°œ")
            
            # Document type statistics
            if db_stats.get('by_document_type'):
                st.markdown("#### ğŸ“ ë¬¸ì„œ ìœ í˜•ë³„ í†µê³„")
                doc_type_cols = st.columns(min(len(db_stats['by_document_type']), 5))
                for idx, (doc_type, count) in enumerate(list(db_stats['by_document_type'].items())[:5]):
                    with doc_type_cols[idx % len(doc_type_cols)]:
                        st.metric(doc_type, f"{count}ê°œ")
            
            # Current document analysis (if available)
            if st.session_state.current_result and st.session_state.current_result.get("success"):
                st.markdown("---")
                st.markdown("### ğŸ“„ í˜„ì¬ ë¬¸ì„œ ë¶„ì„")
                result = st.session_state.current_result
                
                # Create beautiful analysis cards
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ¯ í’ˆì§ˆ ì§€í‘œ")
                    
                    validation = result.get('validation', {})
                    
                    # Quality score visualization
                    quality_score = result.get('quality_score', 0)
                    st.progress(quality_score)
                    
                    # Detailed metrics
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>ìƒì„¸ í‰ê°€</h4>
                        <ul>
                            <li>ì „ì²´ í’ˆì§ˆ: <strong>{quality_score:.1%}</strong></li>
                            <li>ìš©ì–´ ì •í™•ë„: <strong>{validation.get('terms', {}).get('score', 0):.1%}</strong></li>
                            <li>ê·œì • ì¤€ìˆ˜: <strong>{'âœ… ì¤€ìˆ˜' if validation.get('compliance', {}).get('is_compliant') else 'âŒ ë¯¸ì¤€ìˆ˜'}</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown("#### ğŸ“ˆ ë¬¸ì„œ í†µê³„")
                    
                    doc = result.get('final_document', '')
                    
                    # Text statistics
                    char_count = len(doc)
                    word_count = len(doc.split())
                    sentence_count = doc.count('.') + doc.count('!') + doc.count('?')
                    
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>í…ìŠ¤íŠ¸ ë¶„ì„</h4>
                        <ul>
                            <li>ë¬¸ì ìˆ˜: <strong>{char_count:,}</strong></li>
                            <li>ë‹¨ì–´ ìˆ˜: <strong>{word_count:,}</strong></li>
                            <li>ë¬¸ì¥ ìˆ˜: <strong>{sentence_count:,}</strong></li>
                            <li>í‰ê·  ë¬¸ì¥ ê¸¸ì´: <strong>{word_count/max(sentence_count, 1):.1f} ë‹¨ì–´</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Model performance
                st.markdown("#### âš¡ ëª¨ë¸ ì„±ëŠ¥")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ¤– ì‚¬ìš© ëª¨ë¸", result.get('provider', '-'))
                with col2:
                    st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_time', 0):.1f}ì´ˆ")
                with col3:
                    st.metric("ğŸ”„ ë°˜ë³µ íšŸìˆ˜", result.get('iterations', 1))
            else:
                st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        with tab5:
            if st.session_state.history:
                st.markdown("### ğŸ“š ë¬¸ì„œ ìƒì„± ì´ë ¥")
                
                # History filter
                col1, col2 = st.columns([2, 1])
                with col1:
                    search_term = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì´ë ¥ì—ì„œ ê²€ìƒ‰...")
                with col2:
                    sort_order = st.selectbox("ì •ë ¬", ["ìµœì‹ ìˆœ", "ì˜¤ë˜ëœìˆœ", "í’ˆì§ˆìˆœ"])
                
                # Sort history
                sorted_history = st.session_state.history.copy()
                if sort_order == "ìµœì‹ ìˆœ":
                    sorted_history.reverse()
                elif sort_order == "í’ˆì§ˆìˆœ":
                    sorted_history.sort(key=lambda x: x['result'].get('quality_score', 0), reverse=True)
                
                # Filter history
                if search_term:
                    sorted_history = [
                        item for item in sorted_history
                        if search_term.lower() in str(item).lower()
                    ]
                
                # Display history
                for idx, item in enumerate(sorted_history, 1):
                    timestamp = datetime.fromisoformat(item['timestamp'])
                    result = item['result']
                    
                    if result.get('success'):
                        with st.expander(
                            f"ğŸ“„ ë¬¸ì„œ #{idx} | "
                            f"{timestamp.strftime('%Y-%m-%d %H:%M')} | "
                            f"{result.get('provider', 'Unknown')} | "
                            f"í’ˆì§ˆ: {result.get('quality_score', 0):.1%}"
                        ):
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.markdown("**ğŸ“‹ ìš”ì²­ ì •ë³´**")
                                st.write(f"ë¬¸ì„œ ìœ í˜•: {item['input']['document_type']}")
                                st.write(f"í†¤: {item['input']['tone']}")
                                st.write(f"ëª¨ë¸: {result.get('model_used', '-')}")
                                st.write(f"í’ˆì§ˆ: {result.get('quality_score', 0):.1%}")
                                st.write(f"ì‹œê°„: {result.get('total_time', 0):.1f}ì´ˆ")
                            
                            with col2:
                                st.markdown("**ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ**")
                                st.text_area(
                                    "ë¬¸ì„œ ë‚´ìš©",
                                    value=result.get('final_document', ''),
                                    height=200,
                                    label_visibility="collapsed",
                                    key=f"history_{idx}"
                                )
                                
                                col1_btn, col2_btn = st.columns(2)
                                with col1_btn:
                                    st.download_button(
                                        label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                                        data=result.get('final_document', ''),
                                        file_name=f"history_{idx}_{timestamp.strftime('%Y%m%d_%H%M%S')}.txt",
                                        mime="text/plain",
                                        key=f"download_{idx}",
                                        use_container_width=True
                                    )
                                with col2_btn:
                                    if result.get('document_id'):
                                        st.caption(f"ğŸ“Œ DB ID: {result['document_id']}")
            else:
                st.info("ì•„ì§ ìƒì„±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´ ì—¬ê¸°ì— ì´ë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            
            # Export options
            st.markdown("---")
            st.markdown("### ğŸ’¾ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ğŸ“Š JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°", use_container_width=True):
                    try:
                        export_data = self.db.export_data("json")
                        st.download_button(
                            "ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                            data=export_data,
                            file_name=f"adk_writer_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"Export ì˜¤ë¥˜: {str(e)}")
            
            with col2:
                if st.button("ğŸ“‹ CSVë¡œ ë‚´ë³´ë‚´ê¸°", use_container_width=True):
                    try:
                        export_data = self.db.export_data("csv")
                        st.download_button(
                            "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                            data=export_data,
                            file_name=f"adk_writer_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"Export ì˜¤ë¥˜: {str(e)}")
            
            with col3:
                # Database statistics
                try:
                    db_stats = self.db.get_statistics(days=30)
                    st.metric("ğŸ“Š ì „ì²´ ë¬¸ì„œ", f"{db_stats['total_documents']:,}ê°œ")
                except:
                    st.metric("ğŸ“Š ì„¸ì…˜ ë¬¸ì„œ", f"{len(st.session_state.history)}ê°œ")


def main():
    """Main entry point"""
    app = MultiModelFinancialWritingApp()
    app.run()


if __name__ == "__main__":
    main()
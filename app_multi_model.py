"""
Multi-Model AI Financial Writer Pro - Streamlit Cloud Version
Supports Anthropic Claude, OpenAI GPT, and Google Gemini
"""

import streamlit as st
from typing import Dict, Any, Optional
import json
from datetime import datetime
from pathlib import Path
import time

# Page configuration
st.set_page_config(
    page_title="AI Financial Writer Pro - Multi Model",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Try cloud config first, fallback to local
try:
    from src.config_cloud import config
except:
    from src.config import config

from src.agents.multi_model_agents import (
    ModelFactory,
    MultiModelAgent,
    MultiModelAgentResponse
)
from src.agents.loop_agent import LoopAgent
from src.tools.custom_tools import (
    validate_financial_terms,
    check_compliance,
    calculate_quality_score
)

# Custom CSS for modern UI
st.markdown("""
<style>
    /* Main App Styling */
    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    /* Header Styling */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2.5rem;
        border-radius: 20px;
        margin-bottom: 2rem;
        color: white;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        animation: slideDown 0.5s ease-out;
    }
    
    @keyframes slideDown {
        from {
            opacity: 0;
            transform: translateY(-20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Card Styling */
    .stat-card {
        background: white;
        border-radius: 16px;
        padding: 1.5rem;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
        margin-bottom: 1rem;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        border: 1px solid rgba(255, 255, 255, 0.8);
    }
    
    .stat-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }
    
    /* Model Selection Cards */
    .model-selector {
        background: white;
        border-radius: 12px;
        padding: 1rem;
        margin: 0.5rem 0;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .model-selector:hover {
        border-color: #667eea;
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
    }
    
    .model-selector.selected {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: #667eea;
    }
    
    /* Provider Badges */
    .provider-badge {
        display: inline-block;
        padding: 0.4rem 1rem;
        border-radius: 25px;
        font-size: 0.875rem;
        font-weight: 600;
        margin: 0.25rem;
        transition: all 0.3s ease;
    }
    
    .provider-badge:hover {
        transform: scale(1.05);
    }
    
    .anthropic-badge {
        background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);
        color: white;
    }
    
    .openai-badge {
        background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
        color: white;
    }
    
    .google-badge {
        background: linear-gradient(135deg, #4285f4 0%, #34a853 100%);
        color: white;
    }
    
    /* Metric Values */
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: pulse 2s ease-in-out infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.8; }
    }
    
    /* Button Styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.8rem 2rem;
        border-radius: 12px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* Sidebar Styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Tab Styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 12px;
        padding: 0.5rem 1.5rem;
        background: white;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        border-color: #667eea;
        transform: translateY(-2px);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-color: transparent;
    }
    
    /* Success/Error Messages */
    .stSuccess {
        background: linear-gradient(135deg, #00b894 0%, #00cec9 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    .stError {
        background: linear-gradient(135deg, #ff7675 0%, #d63031 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
    }
    
    /* Text Area Styling */
    .stTextArea textarea {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTextArea textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Select Box Styling */
    .stSelectbox > div > div {
        border-radius: 12px;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
</style>
""", unsafe_allow_html=True)

class MultiModelFinancialWritingApp:
    """Multi-Model Financial Writing AI Application"""
    
    def __init__(self):
        self.config = config
        self.multi_model_agent = None
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Initialize session state variables"""
        if 'history' not in st.session_state:
            st.session_state.history = []
        if 'current_result' not in st.session_state:
            st.session_state.current_result = None
        if 'stats' not in st.session_state:
            st.session_state.stats = {
                'total_documents': 0,
                'avg_quality': 0,
                'avg_iterations': 0,
                'total_time': 0,
                'models_used': {}
            }
        if 'selected_provider' not in st.session_state:
            st.session_state.selected_provider = config.DEFAULT_PROVIDER
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = config.ANTHROPIC_MODEL if config.DEFAULT_PROVIDER == "Anthropic" else None
        if 'draft_document' not in st.session_state:
            st.session_state.draft_document = None
        if 'refinement_history' not in st.session_state:
            st.session_state.refinement_history = []
    
    def render_header(self):
        """Render animated header"""
        st.markdown("""
        <div class="main-header">
            <h1 style="margin: 0; font-size: 2.8rem; font-weight: 800;">
                ğŸ¤– AI Financial Writer Pro
            </h1>
            <p style="margin-top: 0.8rem; font-size: 1.2rem; opacity: 0.95;">
                ì°¨ì„¸ëŒ€ ê¸ˆìœµ ë¬¸ì„œ ì‘ì„± AI í”Œë«í¼
            </p>
            <div style="margin-top: 1rem;">
                <span class="provider-badge anthropic-badge">Anthropic Claude</span>
                <span class="provider-badge openai-badge">OpenAI GPT</span>
                <span class="provider-badge google-badge">Google Gemini</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar_model_selector(self):
        """Render model selection in sidebar"""
        st.sidebar.markdown("## ğŸ¤– AI ëª¨ë¸ ì„¤ì •")
        
        available_models = ModelFactory.get_available_models()
        providers_available = []
        
        # Check available providers
        if config.ANTHROPIC_API_KEY:
            providers_available.append("Anthropic")
        if config.OPENAI_API_KEY:
            providers_available.append("OpenAI")
        if config.GOOGLE_API_KEY:
            providers_available.append("Google")
        
        if not providers_available:
            st.sidebar.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return providers_available
        
        # Provider selection
        st.sidebar.markdown("### ğŸ“¦ AI ì œê³µì")
        selected_provider = st.sidebar.radio(
            "ì œê³µì ì„ íƒ",
            options=providers_available,
            index=providers_available.index(st.session_state.selected_provider) if st.session_state.selected_provider in providers_available else 0,
            label_visibility="collapsed",
            help="ì‚¬ìš©í•  AI ì œê³µìë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if selected_provider != st.session_state.selected_provider:
            st.session_state.selected_provider = selected_provider
            st.session_state.selected_model = None
            st.rerun()
        
        # Model selection for current provider
        if selected_provider in available_models:
            st.sidebar.markdown("### ğŸ¯ ëª¨ë¸ ì„ íƒ")
            
            models = available_models[selected_provider]
            model_options = list(models.keys())
            model_labels = list(models.values())
            
            # Set default model index
            if st.session_state.selected_model and st.session_state.selected_model in model_options:
                default_index = model_options.index(st.session_state.selected_model)
            else:
                default_index = 0
                st.session_state.selected_model = model_options[0]
            
            selected_model = st.sidebar.selectbox(
                "ëª¨ë¸",
                options=model_options,
                format_func=lambda x: models[x],
                index=default_index,
                label_visibility="collapsed",
                help="ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            if selected_model != st.session_state.selected_model:
                st.session_state.selected_model = selected_model
            
            # Model features
            with st.sidebar.expander("ğŸŒŸ ëª¨ë¸ íŠ¹ì§•", expanded=False):
                if selected_provider == "Anthropic":
                    st.markdown("""
                    **Claude íŠ¹ì§•:**
                    - ğŸ“š ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (200K í† í°)
                    - ğŸ¯ ë†’ì€ ì •í™•ë„ì™€ ì¼ê´€ì„±
                    - ğŸ’¡ ë›°ì–´ë‚œ ì¶”ë¡  ëŠ¥ë ¥
                    - ğŸ”’ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µ
                    """)
                elif selected_provider == "OpenAI":
                    st.markdown("""
                    **GPT íŠ¹ì§•:**
                    - ğŸŒ ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì›
                    - ğŸ¨ ì°½ì˜ì ì¸ ì½˜í…ì¸  ìƒì„±
                    - ğŸ”§ ê°•ë ¥í•œ ì½”ë“œ ìƒì„±
                    - ğŸ“Š ë°ì´í„° ë¶„ì„ ëŠ¥ë ¥
                    """)
                elif selected_provider == "Google":
                    st.markdown("""
                    **Gemini íŠ¹ì§•:**
                    - âš¡ ë¹ ë¥¸ ì‘ë‹µ ì†ë„
                    - ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ ì§€ì›
                    - ğŸ’° ë¹„ìš© íš¨ìœ¨ì 
                    - ğŸ”„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
                    """)
        
        return providers_available
    
    def render_stats(self):
        """Render animated statistics"""
        st.markdown("### ğŸ“Š í†µê³„")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "ğŸ“„ ì´ ìƒì„± ë¬¸ì„œ",
                st.session_state.stats['total_documents'],
                "+1" if st.session_state.stats['total_documents'] > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            quality_value = st.session_state.stats['avg_quality']
            quality_delta = (quality_value - 0.7) * 100 if quality_value > 0 else 0
            st.metric(
                "â­ í‰ê·  í’ˆì§ˆ",
                f"{quality_value:.1%}",
                f"+{quality_delta:.0f}%" if quality_delta > 0 else None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            st.metric(
                "ğŸ”„ í‰ê·  ë°˜ë³µ",
                f"{st.session_state.stats['avg_iterations']:.1f}íšŒ",
                None
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="stat-card">', unsafe_allow_html=True)
            if st.session_state.stats['models_used']:
                most_used = max(st.session_state.stats['models_used'].items(), key=lambda x: x[1])
                st.metric(
                    "ğŸ† ì£¼ ì‚¬ìš© ëª¨ë¸",
                    most_used[0].split(' - ')[0],
                    f"{most_used[1]}íšŒ"
                )
            else:
                st.metric("ğŸ† ì£¼ ì‚¬ìš© ëª¨ë¸", "-", None)
            st.markdown('</div>', unsafe_allow_html=True)
    
    def process_document(self, input_data: Dict[str, Any], is_refinement: bool = False, use_loop_agent: bool = True) -> Dict[str, Any]:
        """Process document through the pipeline with optional LoopAgent"""
        try:
            # Initialize multi-model agent if not already done
            if not self.multi_model_agent:
                agent_config = config.get_agent_config()
                self.multi_model_agent = MultiModelAgent(agent_config)
            
            # Show progress with animation
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # Get selected provider and model
            provider = st.session_state.selected_provider
            model = st.session_state.selected_model
            
            if model:
                # Update config with selected model
                if provider == "Anthropic":
                    self.multi_model_agent.config['anthropic_model'] = model
                elif provider == "OpenAI":
                    self.multi_model_agent.config['openai_model'] = model
                elif provider == "Google":
                    self.multi_model_agent.config['google_model'] = model
            
            # Animated progress
            with progress_placeholder.container():
                progress_bar = st.progress(0)
                for i in range(0, 101, 5):
                    progress_bar.progress(i)
                    if i < 30:
                        status_placeholder.info(f"ğŸ”§ ëª¨ë¸ ì¤€ë¹„ ì¤‘... ({provider})")
                    elif i < 70:
                        status_placeholder.info(f"âœï¸ ë¬¸ì„œ ìƒì„± ì¤‘... ({provider})")
                    else:
                        status_placeholder.info("ğŸ” í’ˆì§ˆ ê²€ì¦ ì¤‘...")
                    time.sleep(0.1)
            
            # Check if we should use LoopAgent for iterative improvement
            if use_loop_agent and not is_refinement:
                # Use LoopAgent for comprehensive critique and refinement
                status_placeholder.info("ğŸ”„ ADK LoopAgentë¡œ ë¬¸ì„œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì¤‘...")
                
                # Prepare config for LoopAgent
                loop_config = config.get_agent_config()
                loop_config['provider'] = provider
                loop_config['model'] = model
                
                # Create and run LoopAgent
                from src.agents.loop_agent import LoopAgent
                loop_agent = LoopAgent(loop_config)
                
                # Run the loop agent with comprehensive improvement
                loop_result = loop_agent.run({
                    "document_type": input_data.get('document_type'),
                    "context": input_data.get('requirements'),
                    "tone": input_data.get('tone'),
                    "recipient": input_data.get('recipient', ''),
                    "subject": input_data.get('subject', ''),
                    "additional_context": input_data.get('additional_context', ''),
                    "provider": provider,
                    "model": model
                })
                
                # Extract results
                final_doc = loop_result.get('final_document', '')
                quality_score = loop_result.get('quality_score', 0.0)
                iterations = loop_result.get('iterations', 1)
                
                # Save draft from first iteration
                if loop_result.get('history') and len(loop_result['history']) > 0:
                    first_iteration = loop_result['history'][0].get('result', {})
                    draft_doc = first_iteration.get('draft', final_doc)
                    st.session_state.draft_document = draft_doc
                    st.session_state.refinement_history = [{
                        'version': 'ì´ˆì•ˆ',
                        'content': draft_doc,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {model}"
                    }]
                    
                    # Add refinement history from loop iterations
                    for i, hist in enumerate(loop_result['history'][1:], 1):
                        refined_content = hist.get('result', {}).get('refined_content', '')
                        if refined_content:
                            st.session_state.refinement_history.append({
                                'version': f'ê°œì„  {i}',
                                'content': refined_content,
                                'timestamp': hist.get('timestamp', datetime.now().isoformat()),
                                'model': f"{provider} - {model}",
                                'quality_score': hist.get('result', {}).get('quality_score', 0)
                            })
                
                # Update status
                status_placeholder.success(
                    f"âœ… LoopAgent ì™„ë£Œ! "
                    f"ì´ {iterations}íšŒ ë°˜ë³µ, "
                    f"í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}, "
                    f"ì¢…ë£Œ ì‚¬ìœ : {loop_result.get('exit_reason', 'Unknown')}"
                )
                
            else:
                # Simple generation without LoopAgent
                prompt = self._create_prompt(input_data)
                
                # Generate response
                response = self.multi_model_agent.generate(
                    prompt,
                    provider=provider,
                    temperature=input_data.get('temperature', 0.7),
                    max_tokens=input_data.get('max_tokens', 2048)
                )
                
                final_doc = response.content
                
                # Save draft if first generation
                if not is_refinement and not st.session_state.draft_document:
                    st.session_state.draft_document = response.content
                    st.session_state.refinement_history = [{
                        'version': 'ì´ˆì•ˆ',
                        'content': response.content,
                        'timestamp': datetime.now().isoformat(),
                        'model': f"{provider} - {response.model_used}"
                    }]
                
                # Calculate quality score for simple generation
                term_validation = validate_financial_terms(final_doc)
                compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
                quality_score = calculate_quality_score(final_doc, term_validation, compliance_check)
                iterations = 1
            
            # Clear progress
            progress_placeholder.empty()
            status_placeholder.empty()
            
            # Final validation (for all paths)
            term_validation = validate_financial_terms(final_doc)
            compliance_check = check_compliance(final_doc, input_data.get("document_type", "email"))
            final_score = quality_score if use_loop_agent and not is_refinement else calculate_quality_score(final_doc, term_validation, compliance_check)
            
            # Update model usage stats
            model_used = model if use_loop_agent and not is_refinement else response.model_used if 'response' in locals() else model
            model_key = f"{provider} - {model_used}"
            if model_key not in st.session_state.stats['models_used']:
                st.session_state.stats['models_used'][model_key] = 0
            st.session_state.stats['models_used'][model_key] += 1
            
            result = {
                "success": True,
                "final_document": final_doc,
                "quality_score": final_score,
                "iterations": iterations if 'iterations' in locals() else 1,
                "total_time": 5.0,
                "provider": provider,
                "model_used": model_used,
                "validation": {
                    "terms": term_validation,
                    "compliance": compliance_check,
                    "final_score": final_score
                }
            }
            
            # Update stats
            self._update_stats(result)
            
            return result
            
        except Exception as e:
            progress_placeholder.empty()
            status_placeholder.empty()
            return {"error": str(e), "success": False}
    
    def _create_prompt(self, input_data: Dict[str, Any]) -> str:
        """Create prompt for document generation"""
        doc_type = config.DOCUMENT_TYPES.get(input_data['document_type'], input_data['document_type'])
        
        prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸ˆìœµ ë¬¸ì„œ ì‘ì„± AIì…ë‹ˆë‹¤.
        
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” {doc_type}ì„(ë¥¼) ì‘ì„±í•´ì£¼ì„¸ìš”:

ìš”êµ¬ì‚¬í•­: {input_data['requirements']}
í†¤ì•¤ë§¤ë„ˆ: {input_data['tone']}
"""
        
        if input_data.get('recipient'):
            prompt += f"\nìˆ˜ì‹ ì: {input_data['recipient']}"
        
        if input_data.get('subject'):
            prompt += f"\nì œëª©: {input_data['subject']}"
        
        if input_data.get('additional_context'):
            prompt += f"\nì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {input_data['additional_context']}"
        
        prompt += """

ë‹¤ìŒ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ì „ë¬¸ì ì´ê³  ì •í™•í•œ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©
2. ê·œì • ì¤€ìˆ˜ ë° ë²•ì  ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
3. ëª…í™•í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ êµ¬ì„±
4. ì ì ˆí•œ êµ¬ì¡°ì™€ í˜•ì‹
5. ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„
"""
        
        return prompt
    
    def _update_stats(self, result: Dict[str, Any]):
        """Update statistics"""
        stats = st.session_state.stats
        stats['total_documents'] += 1
        
        current_quality = result.get('quality_score', 0)
        stats['avg_quality'] = (
            (stats['avg_quality'] * (stats['total_documents'] - 1) + current_quality) 
            / stats['total_documents']
        )
        
        current_iter = result.get('iterations', 0)
        stats['avg_iterations'] = (
            (stats['avg_iterations'] * (stats['total_documents'] - 1) + current_iter)
            / stats['total_documents']
        )
        
        stats['total_time'] += result.get('total_time', 0)
    
    def run(self):
        """Run the application"""
        # Header
        self.render_header()
        
        # Sidebar with model selection and settings
        with st.sidebar:
            st.markdown("---")
            
            # Model selector in sidebar
            providers_available = self.render_sidebar_model_selector()
            
            if not providers_available:
                st.stop()
            
            st.markdown("---")
            
            # Model settings
            st.markdown("## âš™ï¸ ëª¨ë¸ ì„¤ì •")
            
            temperature = st.slider(
                "ğŸŒ¡ï¸ Temperature (ì°½ì˜ì„±)",
                min_value=0.0,
                max_value=1.0,
                value=config.TEMPERATURE,
                step=0.1,
                help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆê³ , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì…ë‹ˆë‹¤"
            )
            
            max_tokens = st.number_input(
                "ğŸ“ ìµœëŒ€ í† í° ìˆ˜",
                min_value=500,
                max_value=4000,
                value=config.MAX_OUTPUT_TOKENS,
                step=100,
                help="ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´"
            )
            
            st.markdown("---")
            
            # Document settings
            st.markdown("## ğŸ“„ ë¬¸ì„œ ì„¤ì •")
            
            doc_type = st.selectbox(
                "ë¬¸ì„œ ìœ í˜•",
                options=list(config.DOCUMENT_TYPES.keys()),
                format_func=lambda x: config.DOCUMENT_TYPES[x],
                help="ì‘ì„±í•  ë¬¸ì„œì˜ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            tone = st.select_slider(
                "í†¤ì•¤ë§¤ë„ˆ",
                options=["formal", "professional", "professional_friendly", "friendly"],
                value="professional",
                format_func=lambda x: {
                    "formal": "ê²©ì‹ìˆëŠ”",
                    "professional": "ì „ë¬¸ì ì¸",
                    "professional_friendly": "ì „ë¬¸ì ì´ë©´ì„œ ì¹œê·¼í•œ",
                    "friendly": "ì¹œê·¼í•œ"
                }.get(x, x),
                help="ë¬¸ì„œì˜ í†¤ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            st.markdown("---")
            
            # Quick actions
            st.markdown("## ğŸš€ ë¹ ë¥¸ ì‹¤í–‰")
            
            if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.history = []
                st.session_state.current_result = None
                st.rerun()
            
            if st.button("ğŸ“Š í†µê³„ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.stats = {
                    'total_documents': 0,
                    'avg_quality': 0,
                    'avg_iterations': 0,
                    'total_time': 0,
                    'models_used': {}
                }
                st.rerun()
        
        # Main content area
        st.markdown("---")
        
        # Stats dashboard
        self.render_stats()
        
        st.markdown("---")
        
        # Tabs for different features
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "âœï¸ ë¬¸ì„œ ì‘ì„±",
            "ğŸ”„ ì´ˆì•ˆ vs ìµœì¢…",
            "ğŸ” ëª¨ë¸ ë¹„êµ",
            "ğŸ“Š ë¶„ì„",
            "ğŸ“š ì´ë ¥"
        ])
        
        with tab1:
            col1, col2 = st.columns([1, 1], gap="large")
            
            with col1:
                st.markdown("### ğŸ“ ë¬¸ì„œ ìš”êµ¬ì‚¬í•­")
                
                requirements = st.text_area(
                    "ìš”êµ¬ì‚¬í•­",
                    placeholder="ì‘ì„±í•˜ê³ ì í•˜ëŠ” ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”...\n\nì˜ˆì‹œ:\n- ì‹ ê·œ ê¸ˆìœµ ìƒí’ˆ ì•ˆë‚´ ì´ë©”ì¼\n- íˆ¬ì ì œì•ˆì„œ ì´ˆì•ˆ\n- ê·œì • ì¤€ìˆ˜ ë³´ê³ ì„œ",
                    height=250,
                    label_visibility="collapsed"
                )
                
                with st.expander("ğŸ“ ì¶”ê°€ ì •ë³´", expanded=False):
                    recipient = st.text_input("ìˆ˜ì‹ ì", placeholder="ì˜ˆ: ê¹€ì² ìˆ˜ ëŒ€í‘œë‹˜")
                    subject = st.text_input("ì œëª©", placeholder="ì˜ˆ: 2024ë…„ ì‹ ê·œ íˆ¬ì ìƒí’ˆ ì•ˆë‚´")
                    additional_context = st.text_area(
                        "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸",
                        placeholder="íŠ¹ë³„íˆ ê°•ì¡°í•˜ê±°ë‚˜ í¬í•¨í•´ì•¼ í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...",
                        height=100
                    )
                
                # LoopAgent ì‚¬ìš© ì˜µì…˜
                use_loop = st.checkbox(
                    "ğŸ”„ ADK LoopAgentë¡œ ë¹„í‰ ë° ê°œì„  ìˆ˜í–‰",
                    value=True,
                    help="ì²´í¬í•˜ë©´ ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ë²ˆ ë¹„í‰í•˜ê³  ê°œì„ í•˜ì—¬ í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤."
                )
                
                col1_1, col1_2 = st.columns(2)
                with col1_1:
                    if st.button("ğŸš€ ë¬¸ì„œ ìƒì„±", type="primary", use_container_width=True):
                        if requirements:
                            if not st.session_state.selected_model:
                                st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ AI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            else:
                                input_data = {
                                    "document_type": doc_type,
                                    "requirements": requirements,
                                    "tone": tone,
                                    "recipient": recipient,
                                    "subject": subject,
                                    "additional_context": additional_context,
                                    "temperature": temperature,
                                    "max_tokens": max_tokens
                                }
                                
                                result = self.process_document(input_data, use_loop_agent=use_loop)
                                
                                st.session_state.current_result = result
                                st.session_state.history.append({
                                    "timestamp": datetime.now().isoformat(),
                                    "input": input_data,
                                    "result": result
                                })
                                
                                if result.get("success"):
                                    st.success(f"âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ! (ëª¨ë¸: {result.get('model_used', 'Unknown')})")
                                    st.balloons()
                                else:
                                    st.error(f"âŒ ì˜¤ë¥˜: {result.get('error')}")
                        else:
                            st.warning("ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                with col1_2:
                    if st.button("ğŸ² ì˜ˆì‹œ ì…ë ¥", use_container_width=True):
                        st.session_state.example_text = "ê³ ì•¡ ìì‚°ê°€ë¥¼ ìœ„í•œ í”„ë¦¬ë¯¸ì—„ ìì‚°ê´€ë¦¬ ì„œë¹„ìŠ¤ ì•ˆë‚´ ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. VIP ê³ ê° ëŒ€ìƒìœ¼ë¡œ ì „ë¬¸ì ì´ë©´ì„œë„ í’ˆê²©ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë§ì¶¤í˜• í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ì™€ ì„¸ë¬´ ìë¬¸ ì„œë¹„ìŠ¤ë¥¼ ê°•ì¡°í•´ì£¼ì„¸ìš”."
                        st.rerun()
            
            with col2:
                st.markdown("### ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ")
                
                if st.session_state.current_result and st.session_state.current_result.get("success"):
                    result = st.session_state.current_result
                    
                    # Model info badge
                    provider = result.get('provider', 'Unknown')
                    model = result.get('model_used', 'Unknown')
                    
                    col2_1, col2_2 = st.columns([2, 1])
                    with col2_1:
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            <strong>ğŸ¤– {provider}</strong> | {model}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2_2:
                        quality_score = result.get('quality_score', 0)
                        if quality_score >= 0.9:
                            quality_badge = "ğŸ† ìš°ìˆ˜"
                            quality_color = "#00b894"
                        elif quality_score >= 0.8:
                            quality_badge = "âœ… ì–‘í˜¸"
                            quality_color = "#fdcb6e"
                        else:
                            quality_badge = "âš ï¸ ê°œì„ í•„ìš”"
                            quality_color = "#d63031"
                        
                        st.markdown(f"""
                        <div style="padding: 0.5rem; background: {quality_color}; 
                                    color: white; border-radius: 10px; text-align: center; margin-bottom: 1rem;">
                            {quality_badge} {quality_score:.1%}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Document content
                    st.text_area(
                        "ìµœì¢… ë¬¸ì„œ",
                        value=result.get("final_document", ""),
                        height=350,
                        label_visibility="collapsed"
                    )
                    
                    # Metrics
                    col2_1, col2_2, col2_3 = st.columns(3)
                    with col2_1:
                        st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_time', 0):.1f}ì´ˆ")
                    with col2_2:
                        doc_length = len(result.get("final_document", ""))
                        st.metric("ğŸ“ ë¬¸ì„œ ê¸¸ì´", f"{doc_length:,}ì")
                    with col2_3:
                        word_count = len(result.get("final_document", "").split())
                        st.metric("ğŸ“ ë‹¨ì–´ ìˆ˜", f"{word_count:,}ê°œ")
                    
                    # Download button
                    st.download_button(
                        label="ğŸ“¥ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=result["final_document"],
                        file_name=f"document_{provider}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                else:
                    st.info("ğŸ’¡ ì™¼ìª½ì—ì„œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ê³  'ë¬¸ì„œ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                    
                    # Show example if available
                    if hasattr(st.session_state, 'example_text'):
                        st.markdown("#### ì˜ˆì‹œ ìš”êµ¬ì‚¬í•­:")
                        st.info(st.session_state.example_text)
        
        with tab2:
            st.markdown("### ğŸ”„ ì´ˆì•ˆ vs ìµœì¢… ë¬¸ì„œ ë¹„êµ")
            
            if st.session_state.draft_document and st.session_state.current_result:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ“ ì´ˆì•ˆ")
                    st.text_area(
                        "ì´ˆì•ˆ ë¬¸ì„œ",
                        value=st.session_state.draft_document,
                        height=400,
                        label_visibility="collapsed",
                        key="draft_compare"
                    )
                    
                    # Draft metrics
                    draft_terms = validate_financial_terms(st.session_state.draft_document)
                    draft_compliance = check_compliance(st.session_state.draft_document, "email")
                    draft_score = calculate_quality_score(st.session_state.draft_document, draft_terms, draft_compliance)
                    
                    st.metric("ì´ˆì•ˆ í’ˆì§ˆ", f"{draft_score:.1%}")
                    st.metric("ì´ˆì•ˆ ê¸¸ì´", f"{len(st.session_state.draft_document):,}ì")
                
                with col2:
                    st.markdown("#### âœ¨ ìµœì¢… ë¬¸ì„œ")
                    final_doc = st.session_state.current_result.get('final_document', '')
                    st.text_area(
                        "ìµœì¢… ë¬¸ì„œ",
                        value=final_doc,
                        height=400,
                        label_visibility="collapsed",
                        key="final_compare"
                    )
                    
                    # Final metrics
                    final_score = st.session_state.current_result.get('quality_score', 0)
                    st.metric("ìµœì¢… í’ˆì§ˆ", f"{final_score:.1%}")
                    st.metric("ìµœì¢… ê¸¸ì´", f"{len(final_doc):,}ì")
                
                # Improvement analysis
                st.markdown("#### ğŸ“ˆ ê°œì„  ë¶„ì„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    improvement = (final_score - draft_score) * 100
                    if improvement > 0:
                        st.success(f"í’ˆì§ˆ ê°œì„ : +{improvement:.1f}%")
                    elif improvement < 0:
                        st.error(f"í’ˆì§ˆ í•˜ë½: {improvement:.1f}%")
                    else:
                        st.info("í’ˆì§ˆ ë™ì¼")
                
                with col2:
                    length_change = len(final_doc) - len(st.session_state.draft_document)
                    if length_change > 0:
                        st.info(f"ê¸¸ì´ ì¦ê°€: +{length_change:,}ì")
                    elif length_change < 0:
                        st.info(f"ê¸¸ì´ ê°ì†Œ: {length_change:,}ì")
                    else:
                        st.info("ê¸¸ì´ ë™ì¼")
                
                with col3:
                    if st.button("â™»ï¸ ë¬¸ì„œ ì¬ì •ì œ", use_container_width=True):
                        # Refine document again
                        refinement_prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ë” ê°œì„ í•´ì£¼ì„¸ìš”:\n\n{final_doc}"
                        input_data = st.session_state.current_result.get('input', {})
                        input_data['requirements'] = refinement_prompt
                        
                        with st.spinner("ë¬¸ì„œë¥¼ ì¬ì •ì œí•˜ëŠ” ì¤‘..."):
                            refined_result = self.process_document(input_data, is_refinement=True)
                            if refined_result.get('success'):
                                st.session_state.current_result = refined_result
                                st.session_state.refinement_history.append({
                                    'version': f"ì •ì œ {len(st.session_state.refinement_history)}",
                                    'content': refined_result.get('final_document', ''),
                                    'timestamp': datetime.now().isoformat(),
                                    'model': f"{refined_result.get('provider')} - {refined_result.get('model_used')}"
                                })
                                st.success("ë¬¸ì„œê°€ ì¬ì •ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.rerun()
                
                # Refinement history
                if len(st.session_state.refinement_history) > 1:
                    st.markdown("#### ğŸ“š ì •ì œ ì´ë ¥")
                    for idx, version in enumerate(st.session_state.refinement_history):
                        with st.expander(f"{version['version']} - {version['model']}"):
                            st.text_area(
                                f"ë²„ì „ {idx}",
                                value=version['content'][:500] + "...",
                                height=150,
                                label_visibility="collapsed",
                                key=f"version_{idx}"
                            )
            else:
                st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë¬¸ì„œ ì‘ì„± íƒ­ì—ì„œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ê³  ìƒì„± ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        
        with tab3:
            st.markdown("### ğŸ” ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ")
            st.info("ë™ì¼í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”.")
            
            compare_requirements = st.text_area(
                "ë¹„êµí•  ë¬¸ì„œ ìš”êµ¬ì‚¬í•­",
                placeholder="ëª¨ë“  ëª¨ë¸ì—ì„œ í…ŒìŠ¤íŠ¸í•  ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”...",
                height=150,
                key="compare_requirements"
            )
            
            # Model selection for comparison
            st.markdown("#### ë¹„êµí•  ëª¨ë¸ ì„ íƒ")
            col1, col2, col3 = st.columns(3)
            
            compare_models = []
            with col1:
                if config.ANTHROPIC_API_KEY and st.checkbox("Anthropic Claude", value=True):
                    compare_models.append("Anthropic")
            with col2:
                if config.OPENAI_API_KEY and st.checkbox("OpenAI GPT", value=True):
                    compare_models.append("OpenAI")
            with col3:
                if config.GOOGLE_API_KEY and st.checkbox("Google Gemini", value=True):
                    compare_models.append("Google")
            
            if st.button("ğŸ”¬ ì„ íƒí•œ ëª¨ë¸ë¡œ ë¹„êµ ìƒì„±", type="primary", use_container_width=True):
                if compare_requirements and compare_models:
                    if not self.multi_model_agent:
                        agent_config = config.get_agent_config()
                        self.multi_model_agent = MultiModelAgent(agent_config)
                    
                    # Create input data
                    input_data = {
                        "document_type": doc_type,
                        "requirements": compare_requirements,
                        "tone": tone,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    }
                    
                    prompt = self._create_prompt(input_data)
                    
                    # Progress bar for comparison
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = {}
                    for idx, provider in enumerate(compare_models):
                        status_text.text(f"ğŸ¤– {provider} ëª¨ë¸ë¡œ ìƒì„± ì¤‘...")
                        progress_bar.progress((idx + 1) / len(compare_models))
                        
                        try:
                            response = self.multi_model_agent.generate(prompt, provider=provider)
                            results[provider] = response
                        except Exception as e:
                            st.error(f"{provider} ì˜¤ë¥˜: {str(e)}")
                    
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Display comparison results
                    if results:
                        st.markdown("#### ğŸ“Š ë¹„êµ ê²°ê³¼")
                        
                        # Create columns for side-by-side comparison
                        cols = st.columns(len(results))
                        
                        for idx, (provider, response) in enumerate(results.items()):
                            with cols[idx]:
                                st.markdown(f"##### {provider}")
                                
                                # Calculate quality score
                                term_validation = validate_financial_terms(response.content)
                                compliance_check = check_compliance(response.content, doc_type)
                                quality_score = calculate_quality_score(response.content, term_validation, compliance_check)
                                
                                # Quality badge
                                if quality_score >= 0.9:
                                    st.success(f"í’ˆì§ˆ: {quality_score:.1%}")
                                elif quality_score >= 0.8:
                                    st.warning(f"í’ˆì§ˆ: {quality_score:.1%}")
                                else:
                                    st.error(f"í’ˆì§ˆ: {quality_score:.1%}")
                                
                                st.text_area(
                                    f"{provider} ê²°ê³¼",
                                    value=response.content,
                                    height=400,
                                    label_visibility="collapsed",
                                    key=f"compare_{provider}"
                                )
                                
                                st.metric("ëª¨ë¸", response.model_used)
                                st.metric("ë¬¸ì ìˆ˜", f"{len(response.content):,}")
                else:
                    if not compare_requirements:
                        st.warning("ë¹„êµí•  ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    if not compare_models:
                        st.warning("ë¹„êµí•  ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        with tab4:
            if st.session_state.current_result and st.session_state.current_result.get("success"):
                result = st.session_state.current_result
                
                st.markdown("### ğŸ“Š ë¬¸ì„œ ë¶„ì„")
                
                # Create beautiful analysis cards
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ¯ í’ˆì§ˆ ì§€í‘œ")
                    
                    validation = result.get('validation', {})
                    
                    # Quality score visualization
                    quality_score = result.get('quality_score', 0)
                    st.progress(quality_score)
                    
                    # Detailed metrics
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>ìƒì„¸ í‰ê°€</h4>
                        <ul>
                            <li>ì „ì²´ í’ˆì§ˆ: <strong>{quality_score:.1%}</strong></li>
                            <li>ìš©ì–´ ì •í™•ë„: <strong>{validation.get('terms', {}).get('score', 0):.1%}</strong></li>
                            <li>ê·œì • ì¤€ìˆ˜: <strong>{'âœ… ì¤€ìˆ˜' if validation.get('compliance', {}).get('is_compliant') else 'âŒ ë¯¸ì¤€ìˆ˜'}</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown("#### ğŸ“ˆ ë¬¸ì„œ í†µê³„")
                    
                    doc = result.get('final_document', '')
                    
                    # Text statistics
                    char_count = len(doc)
                    word_count = len(doc.split())
                    sentence_count = doc.count('.') + doc.count('!') + doc.count('?')
                    
                    st.markdown(f"""
                    <div class="stat-card">
                        <h4>í…ìŠ¤íŠ¸ ë¶„ì„</h4>
                        <ul>
                            <li>ë¬¸ì ìˆ˜: <strong>{char_count:,}</strong></li>
                            <li>ë‹¨ì–´ ìˆ˜: <strong>{word_count:,}</strong></li>
                            <li>ë¬¸ì¥ ìˆ˜: <strong>{sentence_count:,}</strong></li>
                            <li>í‰ê·  ë¬¸ì¥ ê¸¸ì´: <strong>{word_count/max(sentence_count, 1):.1f} ë‹¨ì–´</strong></li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Model performance
                st.markdown("#### âš¡ ëª¨ë¸ ì„±ëŠ¥")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ¤– ì‚¬ìš© ëª¨ë¸", result.get('provider', '-'))
                with col2:
                    st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result.get('total_time', 0):.1f}ì´ˆ")
                with col3:
                    st.metric("ğŸ”„ ë°˜ë³µ íšŸìˆ˜", result.get('iterations', 1))
            else:
                st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        with tab5:
            if st.session_state.history:
                st.markdown("### ğŸ“š ë¬¸ì„œ ìƒì„± ì´ë ¥")
                
                # History filter
                col1, col2 = st.columns([2, 1])
                with col1:
                    search_term = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì´ë ¥ì—ì„œ ê²€ìƒ‰...")
                with col2:
                    sort_order = st.selectbox("ì •ë ¬", ["ìµœì‹ ìˆœ", "ì˜¤ë˜ëœìˆœ", "í’ˆì§ˆìˆœ"])
                
                # Sort history
                sorted_history = st.session_state.history.copy()
                if sort_order == "ìµœì‹ ìˆœ":
                    sorted_history.reverse()
                elif sort_order == "í’ˆì§ˆìˆœ":
                    sorted_history.sort(key=lambda x: x['result'].get('quality_score', 0), reverse=True)
                
                # Filter history
                if search_term:
                    sorted_history = [
                        item for item in sorted_history
                        if search_term.lower() in str(item).lower()
                    ]
                
                # Display history
                for idx, item in enumerate(sorted_history, 1):
                    timestamp = datetime.fromisoformat(item['timestamp'])
                    result = item['result']
                    
                    if result.get('success'):
                        with st.expander(
                            f"ğŸ“„ ë¬¸ì„œ #{idx} | "
                            f"{timestamp.strftime('%Y-%m-%d %H:%M')} | "
                            f"{result.get('provider', 'Unknown')} | "
                            f"í’ˆì§ˆ: {result.get('quality_score', 0):.1%}"
                        ):
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.markdown("**ğŸ“‹ ìš”ì²­ ì •ë³´**")
                                st.write(f"ë¬¸ì„œ ìœ í˜•: {item['input']['document_type']}")
                                st.write(f"í†¤: {item['input']['tone']}")
                                st.write(f"ëª¨ë¸: {result.get('model_used', '-')}")
                                st.write(f"í’ˆì§ˆ: {result.get('quality_score', 0):.1%}")
                                st.write(f"ì‹œê°„: {result.get('total_time', 0):.1f}ì´ˆ")
                            
                            with col2:
                                st.markdown("**ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ**")
                                st.text_area(
                                    "ë¬¸ì„œ ë‚´ìš©",
                                    value=result.get('final_document', ''),
                                    height=200,
                                    label_visibility="collapsed",
                                    key=f"history_{idx}"
                                )
                                
                                st.download_button(
                                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                                    data=result.get('final_document', ''),
                                    file_name=f"history_{idx}_{timestamp.strftime('%Y%m%d_%H%M%S')}.txt",
                                    mime="text/plain",
                                    key=f"download_{idx}"
                                )
            else:
                st.info("ì•„ì§ ìƒì„±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´ ì—¬ê¸°ì— ì´ë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤.")


def main():
    """Main entry point"""
    app = MultiModelFinancialWritingApp()
    app.run()


if __name__ == "__main__":
    main()